{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Image Forgery Detection",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAonaO7k312G"
      },
      "source": [
        "#**Image Forgery Detection**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbgNkOVSPrAk"
      },
      "source": [
        "!pip install opendatasets --upgrade --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjyJJ_DovxeC"
      },
      "source": [
        "##**Downlaoding the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POH51cHIsPao",
        "outputId": "72b01e6c-d97c-44f9-dee0-cc66710e02ad"
      },
      "source": [
        "import opendatasets as od\n",
        "\n",
        "dataset_url = 'https://www.kaggle.com/divg07/casia-20-image-tampering-detection-dataset'\n",
        "od.download(dataset_url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: aryanbansal2000\n",
            "Your Kaggle Key: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0.00/2.56G [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading casia-20-image-tampering-detection-dataset.zip to ./casia-20-image-tampering-detection-dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2.56G/2.56G [00:37<00:00, 73.1MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-tiAn1ts7iu",
        "outputId": "8c5aabc5-aecb-4235-881c-2889083da42a"
      },
      "source": [
        "import os\n",
        "\n",
        "DATA_DIR = './casia-20-image-tampering-detection-dataset/CASIA2'\n",
        "print(os.listdir(DATA_DIR))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Tp', 'CASIA 2 Groundtruth', 'Au']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOi-PAMFwOlj"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlB80iUtv_Dp"
      },
      "source": [
        "##**Importing Necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "R38fAcjuwfW1",
        "outputId": "03836a54-be69-4bb8-c1d0-626866593328"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "np.random.seed(2)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout,BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from PIL import Image, ImageChops, ImageEnhance\n",
        "import PIL\n",
        "import os\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzr25dDMwDML"
      },
      "source": [
        "##**Error Level Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0OOFLUlww8U"
      },
      "source": [
        "def ELA(img_path, quality=90):\n",
        "    TEMP = 'ela_' + 'temp.jpg'\n",
        "    SCALE = 10\n",
        "    original = Image.open(img_path)\n",
        "    diff=\"\"\n",
        "    try:\n",
        "        original.save(TEMP, quality=90)\n",
        "        temporary = Image.open(TEMP)\n",
        "        diff = ImageChops.difference(original, temporary)\n",
        "        \n",
        "    except:\n",
        "        \n",
        "        original.convert('RGB').save(TEMP, quality=90)\n",
        "        temporary = Image.open(TEMP)\n",
        "        diff = ImageChops.difference(original.convert('RGB'), temporary)\n",
        "        \n",
        "       \n",
        "    d=diff.load()\n",
        "    WIDTH, HEIGHT = diff.size\n",
        "    for x in range(WIDTH):\n",
        "        for y in range(HEIGHT):\n",
        "            d[x, y] = tuple(k * SCALE for k in d[x, y])\n",
        "#     save_path = dataset_path +'ELA_IMAGES/'\n",
        "#     diff.save(save_path+'diff.png')\n",
        "    return diff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgGLiFQkxgWB"
      },
      "source": [
        "dataset_path=\"./casia-20-image-tampering-detection-dataset/CASIA2/\"\n",
        "path_original = 'Au/'\n",
        "path_tampered = 'Tp/'\n",
        "# path_mask='CASIA 2 Groundtruth/'\n",
        "total_original = os.listdir(dataset_path+path_original)\n",
        "total_tampered = os.listdir(dataset_path+path_tampered)\n",
        "# total_mask=os.listdir(dataset_path+path_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og3Gmc9Ryg2h"
      },
      "source": [
        "pristine_images = []\n",
        "for i in total_original:\n",
        "    pristine_images.append(dataset_path+path_original+i)\n",
        "fake_images = []\n",
        "for i in total_tampered:\n",
        "    fake_images.append(dataset_path+path_tampered+i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFEDI2UJz7d1",
        "outputId": "92c23aee-1843-4c95-a480-aa3d8207dfb8"
      },
      "source": [
        "len(total_tampered),len(fake_images)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5125, 5125)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FlE8EoO0AFB"
      },
      "source": [
        "image_size = (224,224)\n",
        "output_path='./'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2ofFoGF0EmQ",
        "outputId": "f5068d95-17fc-4387-ea4e-1a4f19b74012"
      },
      "source": [
        "output_path='./'\n",
        "if not os.path.exists(output_path+\"resized_images/\"):\n",
        "#     os.makedirs(output_path+\"resized_images/fake_masks/\")\n",
        "    os.makedirs(output_path+\"resized_images/fake_images/\")\n",
        "    os.makedirs(output_path+\"resized_images/pristine_images/\")\n",
        "    height = 224\n",
        "    width = 224\n",
        "#     p2=output_path+\"resized_images/fake_masks/\"\n",
        "    p1=output_path+\"resized_images/fake_images/\"\n",
        "    p3=output_path+\"resized_images/pristine_images/\"\n",
        "    j=0\n",
        "    for fake_image in tqdm(total_tampered):\n",
        "        try:\n",
        "            if(j%3):\n",
        "                j+=1\n",
        "                continue\n",
        "            img=Image.open(dataset_path+path_tampered + fake_image).convert(\"RGB\")\n",
        "            img = img.resize((height, width), PIL.Image.ANTIALIAS)\n",
        "            img.save(p1+fake_image)\n",
        "            j+=1\n",
        "        except:\n",
        "            print(\"Encountered Invalid File : \",fake_image)\n",
        "        \n",
        "    j=0\n",
        "    for pristine_image in tqdm(total_original):\n",
        "        try:\n",
        "            if(j%3):\n",
        "                j+=1\n",
        "                continue\n",
        "            img=Image.open(dataset_path+path_original + pristine_image).convert(\"RGB\")\n",
        "            img = img.resize((height, width), PIL.Image.ANTIALIAS)\n",
        "            img.save(p3+pristine_image)\n",
        "            j+=1\n",
        "        except:\n",
        "            print(\"Invalid File : \" ,pristine_image)\n",
        "        \n",
        "        \n",
        "        \n",
        "else:\n",
        "    print('images resized,path exists')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5125/5125 [00:10<00:00, 473.95it/s]\n",
            "  2%|▏         | 169/7492 [00:00<00:17, 407.61it/s]/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 2. Skipping tag 41487\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 41988\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            " 64%|██████▍   | 4810/7492 [00:10<00:06, 393.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Invalid File :  Thumbs.db\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7492/7492 [00:16<00:00, 441.77it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHk9zDGC0jJw"
      },
      "source": [
        "resized_fake_image_path=output_path+\"resized_images/fake_images/\"\n",
        "resized_pristine_image_path=output_path+\"resized_images/pristine_images/\"\n",
        "resized_fake_image=os.listdir(resized_fake_image_path)\n",
        "resized_pristine_image=os.listdir(resized_pristine_image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WbvlBTx0z41",
        "outputId": "99e62840-49b6-4033-f985-c8d3bf5eda02"
      },
      "source": [
        "len(resized_pristine_image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2497"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyleXPLS04b0",
        "outputId": "42e5aaae-0c33-4eed-b270-5b9533e45cf9"
      },
      "source": [
        "ela_images_path=output_path+'ELA_IMAGES/'\n",
        "ela_real=ela_images_path+'Au/'\n",
        "ela_fake=ela_images_path+'Tp/'\n",
        "if not os.path.exists(ela_images_path):\n",
        "    os.makedirs(ela_images_path)\n",
        "    os.mkdir(ela_real)\n",
        "    os.mkdir(ela_fake)\n",
        "    j=0\n",
        "    for i in tqdm(resized_fake_image):\n",
        "        ELA(resized_fake_image_path+i).save(ela_fake+i)\n",
        "        j+=1\n",
        "        if(j==1500):\n",
        "            break\n",
        "    j=0\n",
        "    for i in tqdm(resized_pristine_image):\n",
        "        ELA(resized_pristine_image_path+i).save(ela_real+i)\n",
        "        j+=1\n",
        "        if(j==1500):\n",
        "            break\n",
        "else:\n",
        "    print('Images are already converted to ELA')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 1498/1709 [01:19<00:10, 19.23it/s]\n",
            "  0%|          | 0/2497 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 2/2497 [00:00<02:14, 18.51it/s]\u001b[A\n",
            "  0%|          | 4/2497 [00:00<02:16, 18.32it/s]\u001b[A\n",
            "  0%|          | 6/2497 [00:00<02:17, 18.14it/s]\u001b[A\n",
            "  0%|          | 8/2497 [00:00<02:19, 17.79it/s]\u001b[A\n",
            "  0%|          | 10/2497 [00:00<02:20, 17.64it/s]\u001b[A\n",
            "  0%|          | 12/2497 [00:00<02:21, 17.57it/s]\u001b[A\n",
            "  1%|          | 14/2497 [00:00<02:20, 17.64it/s]\u001b[A\n",
            "  1%|          | 16/2497 [00:00<02:19, 17.83it/s]\u001b[A\n",
            "  1%|          | 18/2497 [00:01<02:19, 17.82it/s]\u001b[A\n",
            "  1%|          | 20/2497 [00:01<02:18, 17.92it/s]\u001b[A\n",
            "  1%|          | 22/2497 [00:01<02:18, 17.86it/s]\u001b[A\n",
            "  1%|          | 24/2497 [00:01<02:17, 17.96it/s]\u001b[A\n",
            "  1%|          | 26/2497 [00:01<02:17, 17.94it/s]\u001b[A\n",
            "  1%|          | 28/2497 [00:01<02:17, 17.94it/s]\u001b[A\n",
            "  1%|          | 30/2497 [00:01<02:15, 18.15it/s]\u001b[A\n",
            "  1%|▏         | 32/2497 [00:01<02:17, 17.97it/s]\u001b[A\n",
            "  1%|▏         | 34/2497 [00:01<02:24, 17.00it/s]\u001b[A\n",
            "  1%|▏         | 36/2497 [00:02<02:32, 16.19it/s]\u001b[A\n",
            "  2%|▏         | 38/2497 [00:02<02:30, 16.32it/s]\u001b[A\n",
            "  2%|▏         | 40/2497 [00:02<02:29, 16.40it/s]\u001b[A\n",
            "  2%|▏         | 42/2497 [00:02<02:27, 16.64it/s]\u001b[A\n",
            "  2%|▏         | 44/2497 [00:02<02:24, 17.00it/s]\u001b[A\n",
            "  2%|▏         | 46/2497 [00:02<02:22, 17.26it/s]\u001b[A\n",
            "  2%|▏         | 48/2497 [00:02<02:19, 17.56it/s]\u001b[A\n",
            "  2%|▏         | 50/2497 [00:02<02:18, 17.64it/s]\u001b[A\n",
            "  2%|▏         | 52/2497 [00:02<02:20, 17.39it/s]\u001b[A\n",
            "  2%|▏         | 54/2497 [00:03<02:18, 17.66it/s]\u001b[A\n",
            "  2%|▏         | 56/2497 [00:03<02:17, 17.81it/s]\u001b[A\n",
            "  2%|▏         | 58/2497 [00:03<02:15, 17.95it/s]\u001b[A\n",
            "  2%|▏         | 60/2497 [00:03<02:16, 17.83it/s]\u001b[A\n",
            "  2%|▏         | 62/2497 [00:03<02:16, 17.84it/s]\u001b[A\n",
            "  3%|▎         | 64/2497 [00:03<02:16, 17.84it/s]\u001b[A\n",
            "  3%|▎         | 66/2497 [00:03<02:16, 17.80it/s]\u001b[A\n",
            "  3%|▎         | 68/2497 [00:03<02:18, 17.51it/s]\u001b[A\n",
            "  3%|▎         | 70/2497 [00:03<02:20, 17.31it/s]\u001b[A\n",
            "  3%|▎         | 72/2497 [00:04<02:18, 17.47it/s]\u001b[A\n",
            "  3%|▎         | 74/2497 [00:04<02:19, 17.40it/s]\u001b[A\n",
            "  3%|▎         | 76/2497 [00:04<02:16, 17.67it/s]\u001b[A\n",
            "  3%|▎         | 78/2497 [00:04<02:16, 17.74it/s]\u001b[A\n",
            "  3%|▎         | 80/2497 [00:04<02:16, 17.67it/s]\u001b[A\n",
            "  3%|▎         | 82/2497 [00:04<02:17, 17.57it/s]\u001b[A\n",
            "  3%|▎         | 84/2497 [00:04<02:16, 17.63it/s]\u001b[A\n",
            "  3%|▎         | 86/2497 [00:04<02:15, 17.74it/s]\u001b[A\n",
            "  4%|▎         | 88/2497 [00:05<02:18, 17.43it/s]\u001b[A\n",
            "  4%|▎         | 90/2497 [00:05<02:18, 17.38it/s]\u001b[A\n",
            "  4%|▎         | 92/2497 [00:05<02:17, 17.46it/s]\u001b[A\n",
            "  4%|▍         | 94/2497 [00:05<02:17, 17.48it/s]\u001b[A\n",
            "  4%|▍         | 96/2497 [00:05<02:18, 17.38it/s]\u001b[A\n",
            "  4%|▍         | 98/2497 [00:05<02:16, 17.53it/s]\u001b[A\n",
            "  4%|▍         | 100/2497 [00:05<02:14, 17.78it/s]\u001b[A\n",
            "  4%|▍         | 102/2497 [00:05<02:16, 17.52it/s]\u001b[A\n",
            "  4%|▍         | 104/2497 [00:05<02:15, 17.60it/s]\u001b[A\n",
            "  4%|▍         | 106/2497 [00:06<02:16, 17.56it/s]\u001b[A\n",
            "  4%|▍         | 108/2497 [00:06<02:15, 17.57it/s]\u001b[A\n",
            "  4%|▍         | 110/2497 [00:06<02:14, 17.79it/s]\u001b[A\n",
            "  4%|▍         | 112/2497 [00:06<02:15, 17.59it/s]\u001b[A\n",
            "  5%|▍         | 114/2497 [00:06<02:14, 17.71it/s]\u001b[A\n",
            "  5%|▍         | 116/2497 [00:06<02:14, 17.70it/s]\u001b[A\n",
            "  5%|▍         | 118/2497 [00:06<02:13, 17.80it/s]\u001b[A\n",
            "  5%|▍         | 120/2497 [00:06<02:17, 17.31it/s]\u001b[A\n",
            "  5%|▍         | 122/2497 [00:06<02:16, 17.36it/s]\u001b[A\n",
            "  5%|▍         | 124/2497 [00:07<02:19, 16.98it/s]\u001b[A\n",
            "  5%|▌         | 126/2497 [00:07<02:15, 17.46it/s]\u001b[A\n",
            "  5%|▌         | 128/2497 [00:07<02:12, 17.88it/s]\u001b[A\n",
            "  5%|▌         | 130/2497 [00:07<02:12, 17.92it/s]\u001b[A\n",
            "  5%|▌         | 132/2497 [00:07<02:11, 17.92it/s]\u001b[A\n",
            "  5%|▌         | 134/2497 [00:07<02:12, 17.81it/s]\u001b[A\n",
            "  5%|▌         | 136/2497 [00:07<02:11, 17.96it/s]\u001b[A\n",
            "  6%|▌         | 138/2497 [00:07<02:10, 18.03it/s]\u001b[A\n",
            "  6%|▌         | 140/2497 [00:07<02:10, 18.01it/s]\u001b[A\n",
            "  6%|▌         | 142/2497 [00:08<02:12, 17.71it/s]\u001b[A\n",
            "  6%|▌         | 144/2497 [00:08<02:14, 17.44it/s]\u001b[A\n",
            "  6%|▌         | 146/2497 [00:08<02:12, 17.69it/s]\u001b[A\n",
            "  6%|▌         | 148/2497 [00:08<02:12, 17.76it/s]\u001b[A\n",
            "  6%|▌         | 150/2497 [00:08<02:11, 17.81it/s]\u001b[A\n",
            "  6%|▌         | 152/2497 [00:08<02:10, 18.01it/s]\u001b[A\n",
            "  6%|▌         | 154/2497 [00:08<02:10, 17.90it/s]\u001b[A\n",
            "  6%|▌         | 156/2497 [00:08<02:11, 17.82it/s]\u001b[A\n",
            "  6%|▋         | 158/2497 [00:08<02:10, 17.98it/s]\u001b[A\n",
            "  6%|▋         | 160/2497 [00:09<02:11, 17.81it/s]\u001b[A\n",
            "  6%|▋         | 162/2497 [00:09<02:10, 17.83it/s]\u001b[A\n",
            "  7%|▋         | 164/2497 [00:09<02:09, 18.01it/s]\u001b[A\n",
            "  7%|▋         | 166/2497 [00:09<02:09, 18.00it/s]\u001b[A\n",
            "  7%|▋         | 168/2497 [00:09<02:10, 17.85it/s]\u001b[A\n",
            "  7%|▋         | 170/2497 [00:09<02:09, 17.95it/s]\u001b[A\n",
            "  7%|▋         | 172/2497 [00:09<02:10, 17.83it/s]\u001b[A\n",
            "  7%|▋         | 174/2497 [00:09<02:10, 17.85it/s]\u001b[A\n",
            "  7%|▋         | 176/2497 [00:09<02:09, 17.94it/s]\u001b[A\n",
            "  7%|▋         | 178/2497 [00:10<02:09, 17.92it/s]\u001b[A\n",
            "  7%|▋         | 180/2497 [00:10<02:08, 18.06it/s]\u001b[A\n",
            " 88%|████████▊ | 1498/1709 [01:30<00:10, 19.23it/s]\n",
            "  7%|▋         | 184/2497 [00:10<02:09, 17.80it/s]\u001b[A\n",
            "  7%|▋         | 186/2497 [00:10<02:08, 17.93it/s]\u001b[A\n",
            "  8%|▊         | 188/2497 [00:10<02:10, 17.73it/s]\u001b[A\n",
            "  8%|▊         | 190/2497 [00:10<02:12, 17.39it/s]\u001b[A\n",
            "  8%|▊         | 192/2497 [00:10<02:12, 17.35it/s]\u001b[A\n",
            "  8%|▊         | 194/2497 [00:11<02:12, 17.34it/s]\u001b[A\n",
            "  8%|▊         | 196/2497 [00:11<02:13, 17.29it/s]\u001b[A\n",
            "  8%|▊         | 198/2497 [00:11<02:13, 17.28it/s]\u001b[A\n",
            "  8%|▊         | 200/2497 [00:11<02:11, 17.44it/s]\u001b[A\n",
            "  8%|▊         | 202/2497 [00:11<02:11, 17.44it/s]\u001b[A\n",
            "  8%|▊         | 204/2497 [00:11<02:10, 17.53it/s]\u001b[A\n",
            "  8%|▊         | 206/2497 [00:11<02:09, 17.67it/s]\u001b[A\n",
            "  8%|▊         | 208/2497 [00:11<02:09, 17.63it/s]\u001b[A\n",
            "  8%|▊         | 210/2497 [00:11<02:09, 17.66it/s]\u001b[A\n",
            "  8%|▊         | 212/2497 [00:12<02:08, 17.81it/s]\u001b[A\n",
            "  9%|▊         | 214/2497 [00:12<02:10, 17.48it/s]\u001b[A\n",
            "  9%|▊         | 216/2497 [00:12<02:11, 17.38it/s]\u001b[A\n",
            "  9%|▊         | 218/2497 [00:12<02:09, 17.64it/s]\u001b[A\n",
            "  9%|▉         | 220/2497 [00:12<02:12, 17.23it/s]\u001b[A\n",
            "  9%|▉         | 222/2497 [00:12<02:11, 17.32it/s]\u001b[A\n",
            "  9%|▉         | 224/2497 [00:12<02:10, 17.46it/s]\u001b[A\n",
            "  9%|▉         | 226/2497 [00:12<02:09, 17.52it/s]\u001b[A\n",
            "  9%|▉         | 228/2497 [00:12<02:10, 17.38it/s]\u001b[A\n",
            "  9%|▉         | 230/2497 [00:13<02:09, 17.46it/s]\u001b[A\n",
            "  9%|▉         | 232/2497 [00:13<02:09, 17.46it/s]\u001b[A\n",
            "  9%|▉         | 234/2497 [00:13<02:08, 17.61it/s]\u001b[A\n",
            "  9%|▉         | 236/2497 [00:13<02:10, 17.28it/s]\u001b[A\n",
            " 10%|▉         | 238/2497 [00:13<02:09, 17.51it/s]\u001b[A\n",
            " 10%|▉         | 240/2497 [00:13<02:07, 17.77it/s]\u001b[A\n",
            " 10%|▉         | 242/2497 [00:13<02:06, 17.85it/s]\u001b[A\n",
            " 10%|▉         | 244/2497 [00:13<02:06, 17.81it/s]\u001b[A\n",
            " 10%|▉         | 246/2497 [00:13<02:08, 17.52it/s]\u001b[A\n",
            " 10%|▉         | 248/2497 [00:14<02:07, 17.70it/s]\u001b[A\n",
            " 10%|█         | 250/2497 [00:14<02:08, 17.52it/s]\u001b[A\n",
            " 10%|█         | 252/2497 [00:14<02:06, 17.73it/s]\u001b[A\n",
            " 10%|█         | 254/2497 [00:14<02:06, 17.69it/s]\u001b[A\n",
            " 10%|█         | 256/2497 [00:14<02:07, 17.64it/s]\u001b[A\n",
            " 10%|█         | 258/2497 [00:14<02:06, 17.72it/s]\u001b[A\n",
            " 10%|█         | 260/2497 [00:14<02:05, 17.83it/s]\u001b[A\n",
            " 10%|█         | 262/2497 [00:14<02:04, 17.93it/s]\u001b[A\n",
            " 11%|█         | 264/2497 [00:14<02:05, 17.84it/s]\u001b[A\n",
            " 11%|█         | 266/2497 [00:15<02:04, 17.92it/s]\u001b[A\n",
            " 11%|█         | 268/2497 [00:15<02:06, 17.57it/s]\u001b[A\n",
            " 11%|█         | 270/2497 [00:15<02:05, 17.77it/s]\u001b[A\n",
            " 11%|█         | 272/2497 [00:15<02:04, 17.87it/s]\u001b[A\n",
            " 11%|█         | 274/2497 [00:15<02:05, 17.75it/s]\u001b[A\n",
            " 11%|█         | 276/2497 [00:15<02:04, 17.80it/s]\u001b[A\n",
            " 11%|█         | 278/2497 [00:15<02:05, 17.75it/s]\u001b[A\n",
            " 11%|█         | 280/2497 [00:15<02:04, 17.84it/s]\u001b[A\n",
            " 11%|█▏        | 282/2497 [00:15<02:04, 17.72it/s]\u001b[A\n",
            " 11%|█▏        | 284/2497 [00:16<02:06, 17.46it/s]\u001b[A\n",
            " 11%|█▏        | 286/2497 [00:16<02:07, 17.30it/s]\u001b[A\n",
            " 12%|█▏        | 288/2497 [00:16<02:05, 17.63it/s]\u001b[A\n",
            " 12%|█▏        | 290/2497 [00:16<02:05, 17.63it/s]\u001b[A\n",
            " 12%|█▏        | 292/2497 [00:16<02:02, 17.95it/s]\u001b[A\n",
            " 12%|█▏        | 294/2497 [00:16<02:02, 18.01it/s]\u001b[A\n",
            " 12%|█▏        | 296/2497 [00:16<02:04, 17.75it/s]\u001b[A\n",
            " 12%|█▏        | 298/2497 [00:16<02:05, 17.56it/s]\u001b[A\n",
            " 12%|█▏        | 300/2497 [00:17<02:03, 17.79it/s]\u001b[A\n",
            " 12%|█▏        | 302/2497 [00:17<02:02, 17.91it/s]\u001b[A\n",
            " 12%|█▏        | 304/2497 [00:17<02:04, 17.61it/s]\u001b[A\n",
            " 12%|█▏        | 306/2497 [00:17<02:04, 17.54it/s]\u001b[A\n",
            " 12%|█▏        | 308/2497 [00:17<02:05, 17.42it/s]\u001b[A\n",
            " 12%|█▏        | 310/2497 [00:17<02:04, 17.55it/s]\u001b[A\n",
            " 12%|█▏        | 312/2497 [00:17<02:04, 17.53it/s]\u001b[A\n",
            " 13%|█▎        | 314/2497 [00:17<02:03, 17.72it/s]\u001b[A\n",
            " 13%|█▎        | 316/2497 [00:17<02:04, 17.52it/s]\u001b[A\n",
            " 13%|█▎        | 318/2497 [00:18<02:03, 17.70it/s]\u001b[A\n",
            " 13%|█▎        | 320/2497 [00:18<02:02, 17.70it/s]\u001b[A\n",
            " 13%|█▎        | 322/2497 [00:18<02:05, 17.39it/s]\u001b[A\n",
            " 13%|█▎        | 324/2497 [00:18<02:05, 17.27it/s]\u001b[A\n",
            " 13%|█▎        | 326/2497 [00:18<02:07, 16.97it/s]\u001b[A\n",
            " 13%|█▎        | 328/2497 [00:18<02:05, 17.31it/s]\u001b[A\n",
            " 13%|█▎        | 330/2497 [00:18<02:03, 17.50it/s]\u001b[A\n",
            " 13%|█▎        | 332/2497 [00:18<02:02, 17.68it/s]\u001b[A\n",
            " 13%|█▎        | 334/2497 [00:18<02:01, 17.82it/s]\u001b[A\n",
            " 13%|█▎        | 336/2497 [00:19<01:59, 18.06it/s]\u001b[A\n",
            " 14%|█▎        | 338/2497 [00:19<02:03, 17.49it/s]\u001b[A\n",
            " 14%|█▎        | 340/2497 [00:19<02:02, 17.62it/s]\u001b[A\n",
            " 14%|█▎        | 342/2497 [00:19<02:02, 17.66it/s]\u001b[A\n",
            " 14%|█▍        | 344/2497 [00:19<02:02, 17.60it/s]\u001b[A\n",
            " 14%|█▍        | 346/2497 [00:19<02:01, 17.73it/s]\u001b[A\n",
            " 14%|█▍        | 348/2497 [00:19<02:00, 17.82it/s]\u001b[A\n",
            " 14%|█▍        | 350/2497 [00:19<02:00, 17.82it/s]\u001b[A\n",
            " 14%|█▍        | 352/2497 [00:19<02:01, 17.64it/s]\u001b[A\n",
            " 14%|█▍        | 354/2497 [00:20<02:00, 17.80it/s]\u001b[A\n",
            " 14%|█▍        | 356/2497 [00:20<02:01, 17.63it/s]\u001b[A\n",
            " 14%|█▍        | 358/2497 [00:20<02:01, 17.66it/s]\u001b[A\n",
            " 14%|█▍        | 360/2497 [00:20<02:01, 17.64it/s]\u001b[A\n",
            " 14%|█▍        | 362/2497 [00:20<02:04, 17.19it/s]\u001b[A\n",
            " 15%|█▍        | 364/2497 [00:20<02:01, 17.49it/s]\u001b[A\n",
            " 15%|█▍        | 366/2497 [00:20<02:02, 17.33it/s]\u001b[A\n",
            " 15%|█▍        | 368/2497 [00:20<02:02, 17.41it/s]\u001b[A\n",
            " 15%|█▍        | 370/2497 [00:21<02:01, 17.47it/s]\u001b[A\n",
            " 15%|█▍        | 372/2497 [00:21<02:01, 17.55it/s]\u001b[A\n",
            " 15%|█▍        | 374/2497 [00:21<02:01, 17.41it/s]\u001b[A\n",
            " 15%|█▌        | 376/2497 [00:21<02:00, 17.65it/s]\u001b[A\n",
            " 15%|█▌        | 378/2497 [00:21<02:00, 17.54it/s]\u001b[A\n",
            " 15%|█▌        | 380/2497 [00:21<01:59, 17.69it/s]\u001b[A\n",
            " 15%|█▌        | 382/2497 [00:21<01:58, 17.86it/s]\u001b[A\n",
            " 15%|█▌        | 384/2497 [00:21<01:59, 17.68it/s]\u001b[A\n",
            " 15%|█▌        | 386/2497 [00:21<02:01, 17.34it/s]\u001b[A\n",
            " 16%|█▌        | 388/2497 [00:22<02:01, 17.39it/s]\u001b[A\n",
            " 16%|█▌        | 390/2497 [00:22<01:59, 17.58it/s]\u001b[A\n",
            " 16%|█▌        | 392/2497 [00:22<02:01, 17.28it/s]\u001b[A\n",
            " 16%|█▌        | 394/2497 [00:22<02:00, 17.46it/s]\u001b[A\n",
            " 16%|█▌        | 396/2497 [00:22<02:00, 17.41it/s]\u001b[A\n",
            " 16%|█▌        | 398/2497 [00:22<01:59, 17.57it/s]\u001b[A\n",
            " 16%|█▌        | 400/2497 [00:22<01:59, 17.49it/s]\u001b[A\n",
            " 16%|█▌        | 402/2497 [00:22<01:58, 17.70it/s]\u001b[A\n",
            " 16%|█▌        | 404/2497 [00:22<02:03, 16.99it/s]\u001b[A\n",
            " 16%|█▋        | 406/2497 [00:23<02:02, 17.12it/s]\u001b[A\n",
            " 16%|█▋        | 408/2497 [00:23<02:02, 17.12it/s]\u001b[A\n",
            " 16%|█▋        | 410/2497 [00:23<02:02, 17.08it/s]\u001b[A\n",
            " 16%|█▋        | 412/2497 [00:23<01:59, 17.41it/s]\u001b[A\n",
            " 17%|█▋        | 414/2497 [00:23<02:00, 17.31it/s]\u001b[A\n",
            " 17%|█▋        | 416/2497 [00:23<01:59, 17.41it/s]\u001b[A\n",
            " 17%|█▋        | 418/2497 [00:23<01:58, 17.56it/s]\u001b[A\n",
            " 17%|█▋        | 420/2497 [00:23<01:58, 17.51it/s]\u001b[A\n",
            " 17%|█▋        | 422/2497 [00:23<01:59, 17.41it/s]\u001b[A\n",
            " 17%|█▋        | 424/2497 [00:24<02:00, 17.17it/s]\u001b[A\n",
            " 17%|█▋        | 426/2497 [00:24<01:58, 17.45it/s]\u001b[A\n",
            " 17%|█▋        | 428/2497 [00:24<01:58, 17.43it/s]\u001b[A\n",
            " 17%|█▋        | 430/2497 [00:24<01:57, 17.60it/s]\u001b[A\n",
            " 17%|█▋        | 432/2497 [00:24<01:56, 17.66it/s]\u001b[A\n",
            " 17%|█▋        | 434/2497 [00:24<01:56, 17.69it/s]\u001b[A\n",
            " 17%|█▋        | 436/2497 [00:24<01:56, 17.70it/s]\u001b[A\n",
            " 18%|█▊        | 438/2497 [00:24<01:55, 17.76it/s]\u001b[A\n",
            " 18%|█▊        | 440/2497 [00:25<01:55, 17.82it/s]\u001b[A\n",
            " 18%|█▊        | 442/2497 [00:25<01:56, 17.66it/s]\u001b[A\n",
            " 18%|█▊        | 444/2497 [00:25<01:58, 17.29it/s]\u001b[A\n",
            " 18%|█▊        | 446/2497 [00:25<02:00, 17.00it/s]\u001b[A\n",
            " 18%|█▊        | 448/2497 [00:25<02:00, 17.07it/s]\u001b[A\n",
            " 18%|█▊        | 450/2497 [00:25<01:57, 17.38it/s]\u001b[A\n",
            " 18%|█▊        | 452/2497 [00:25<01:56, 17.58it/s]\u001b[A\n",
            " 18%|█▊        | 454/2497 [00:25<01:56, 17.59it/s]\u001b[A\n",
            " 18%|█▊        | 456/2497 [00:25<01:58, 17.25it/s]\u001b[A\n",
            " 18%|█▊        | 458/2497 [00:26<01:56, 17.46it/s]\u001b[A\n",
            " 18%|█▊        | 460/2497 [00:26<01:55, 17.57it/s]\u001b[A\n",
            " 19%|█▊        | 462/2497 [00:26<01:59, 17.03it/s]\u001b[A\n",
            " 19%|█▊        | 464/2497 [00:26<01:58, 17.23it/s]\u001b[A\n",
            " 19%|█▊        | 466/2497 [00:26<01:57, 17.24it/s]\u001b[A\n",
            " 19%|█▊        | 468/2497 [00:26<01:55, 17.55it/s]\u001b[A\n",
            " 19%|█▉        | 470/2497 [00:26<01:54, 17.65it/s]\u001b[A\n",
            " 19%|█▉        | 472/2497 [00:26<01:54, 17.70it/s]\u001b[A\n",
            " 19%|█▉        | 474/2497 [00:26<01:56, 17.37it/s]\u001b[A\n",
            " 19%|█▉        | 476/2497 [00:27<01:56, 17.37it/s]\u001b[A\n",
            " 19%|█▉        | 478/2497 [00:27<01:55, 17.49it/s]\u001b[A\n",
            " 19%|█▉        | 480/2497 [00:27<01:56, 17.33it/s]\u001b[A\n",
            " 19%|█▉        | 482/2497 [00:27<01:55, 17.39it/s]\u001b[A\n",
            " 19%|█▉        | 484/2497 [00:27<01:56, 17.23it/s]\u001b[A\n",
            " 19%|█▉        | 486/2497 [00:27<01:57, 17.15it/s]\u001b[A\n",
            " 20%|█▉        | 488/2497 [00:27<01:55, 17.39it/s]\u001b[A\n",
            " 20%|█▉        | 490/2497 [00:27<01:57, 17.14it/s]\u001b[A\n",
            " 20%|█▉        | 492/2497 [00:28<01:59, 16.80it/s]\u001b[A\n",
            " 20%|█▉        | 494/2497 [00:28<01:58, 16.90it/s]\u001b[A\n",
            " 20%|█▉        | 496/2497 [00:28<01:56, 17.15it/s]\u001b[A\n",
            " 20%|█▉        | 498/2497 [00:28<02:00, 16.55it/s]\u001b[A\n",
            " 20%|██        | 500/2497 [00:28<02:00, 16.53it/s]\u001b[A\n",
            " 20%|██        | 502/2497 [00:28<02:00, 16.62it/s]\u001b[A\n",
            " 20%|██        | 504/2497 [00:28<01:57, 17.00it/s]\u001b[A\n",
            " 20%|██        | 506/2497 [00:28<01:56, 17.12it/s]\u001b[A\n",
            " 20%|██        | 508/2497 [00:28<01:55, 17.21it/s]\u001b[A\n",
            " 20%|██        | 510/2497 [00:29<01:54, 17.37it/s]\u001b[A\n",
            " 21%|██        | 512/2497 [00:29<01:55, 17.19it/s]\u001b[A\n",
            " 21%|██        | 514/2497 [00:29<01:55, 17.18it/s]\u001b[A\n",
            " 21%|██        | 516/2497 [00:29<01:56, 17.08it/s]\u001b[A\n",
            " 21%|██        | 518/2497 [00:29<01:55, 17.17it/s]\u001b[A\n",
            " 21%|██        | 520/2497 [00:29<01:54, 17.31it/s]\u001b[A\n",
            " 21%|██        | 522/2497 [00:29<01:53, 17.48it/s]\u001b[A\n",
            " 21%|██        | 524/2497 [00:29<01:53, 17.40it/s]\u001b[A\n",
            " 21%|██        | 526/2497 [00:29<01:54, 17.29it/s]\u001b[A\n",
            " 21%|██        | 528/2497 [00:30<01:52, 17.48it/s]\u001b[A\n",
            " 21%|██        | 530/2497 [00:30<01:54, 17.18it/s]\u001b[A\n",
            " 21%|██▏       | 532/2497 [00:30<02:00, 16.32it/s]\u001b[A\n",
            " 21%|██▏       | 534/2497 [00:30<01:56, 16.87it/s]\u001b[A\n",
            " 21%|██▏       | 536/2497 [00:30<01:53, 17.30it/s]\u001b[A\n",
            " 22%|██▏       | 538/2497 [00:30<01:54, 17.10it/s]\u001b[A\n",
            " 22%|██▏       | 540/2497 [00:30<01:55, 17.00it/s]\u001b[A\n",
            " 22%|██▏       | 542/2497 [00:30<01:52, 17.32it/s]\u001b[A\n",
            " 22%|██▏       | 544/2497 [00:31<01:51, 17.45it/s]\u001b[A\n",
            " 22%|██▏       | 546/2497 [00:31<01:53, 17.22it/s]\u001b[A\n",
            " 22%|██▏       | 548/2497 [00:31<01:52, 17.40it/s]\u001b[A\n",
            " 22%|██▏       | 550/2497 [00:31<01:52, 17.34it/s]\u001b[A\n",
            " 22%|██▏       | 552/2497 [00:31<01:52, 17.35it/s]\u001b[A\n",
            " 22%|██▏       | 554/2497 [00:31<01:52, 17.26it/s]\u001b[A\n",
            " 22%|██▏       | 556/2497 [00:31<01:50, 17.56it/s]\u001b[A\n",
            " 22%|██▏       | 558/2497 [00:31<01:50, 17.53it/s]\u001b[A\n",
            " 22%|██▏       | 560/2497 [00:31<01:51, 17.43it/s]\u001b[A\n",
            " 23%|██▎       | 562/2497 [00:32<01:51, 17.28it/s]\u001b[A\n",
            " 23%|██▎       | 564/2497 [00:32<01:51, 17.29it/s]\u001b[A\n",
            " 23%|██▎       | 566/2497 [00:32<01:51, 17.29it/s]\u001b[A\n",
            " 23%|██▎       | 568/2497 [00:32<01:57, 16.43it/s]\u001b[A\n",
            " 23%|██▎       | 570/2497 [00:32<01:55, 16.62it/s]\u001b[A\n",
            " 23%|██▎       | 572/2497 [00:32<01:54, 16.77it/s]\u001b[A\n",
            " 23%|██▎       | 574/2497 [00:32<01:53, 16.90it/s]\u001b[A\n",
            " 23%|██▎       | 576/2497 [00:32<01:54, 16.82it/s]\u001b[A\n",
            " 23%|██▎       | 578/2497 [00:33<01:52, 17.07it/s]\u001b[A\n",
            " 23%|██▎       | 580/2497 [00:33<01:50, 17.29it/s]\u001b[A\n",
            " 23%|██▎       | 582/2497 [00:33<01:50, 17.37it/s]\u001b[A\n",
            " 23%|██▎       | 584/2497 [00:33<01:50, 17.33it/s]\u001b[A\n",
            " 23%|██▎       | 586/2497 [00:33<01:52, 16.92it/s]\u001b[A\n",
            " 24%|██▎       | 588/2497 [00:33<01:52, 17.03it/s]\u001b[A\n",
            " 24%|██▎       | 590/2497 [00:33<01:51, 17.15it/s]\u001b[A\n",
            " 24%|██▎       | 592/2497 [00:33<01:49, 17.35it/s]\u001b[A\n",
            " 24%|██▍       | 594/2497 [00:33<01:49, 17.31it/s]\u001b[A\n",
            " 24%|██▍       | 596/2497 [00:34<01:49, 17.34it/s]\u001b[A\n",
            " 24%|██▍       | 598/2497 [00:34<01:49, 17.40it/s]\u001b[A\n",
            " 24%|██▍       | 600/2497 [00:34<01:47, 17.72it/s]\u001b[A\n",
            " 24%|██▍       | 602/2497 [00:34<01:49, 17.26it/s]\u001b[A\n",
            " 24%|██▍       | 604/2497 [00:34<01:51, 16.91it/s]\u001b[A\n",
            " 24%|██▍       | 606/2497 [00:34<01:49, 17.26it/s]\u001b[A\n",
            " 24%|██▍       | 608/2497 [00:34<01:47, 17.61it/s]\u001b[A\n",
            " 24%|██▍       | 610/2497 [00:34<01:46, 17.70it/s]\u001b[A\n",
            " 25%|██▍       | 612/2497 [00:34<01:47, 17.52it/s]\u001b[A\n",
            " 25%|██▍       | 614/2497 [00:35<01:46, 17.63it/s]\u001b[A\n",
            " 25%|██▍       | 616/2497 [00:35<01:47, 17.44it/s]\u001b[A\n",
            " 25%|██▍       | 618/2497 [00:35<01:49, 17.22it/s]\u001b[A\n",
            " 25%|██▍       | 620/2497 [00:35<01:50, 17.03it/s]\u001b[A\n",
            " 25%|██▍       | 622/2497 [00:35<01:49, 17.14it/s]\u001b[A\n",
            " 25%|██▍       | 624/2497 [00:35<01:47, 17.44it/s]\u001b[A\n",
            " 25%|██▌       | 626/2497 [00:35<01:48, 17.23it/s]\u001b[A\n",
            " 25%|██▌       | 628/2497 [00:35<01:47, 17.46it/s]\u001b[A\n",
            " 25%|██▌       | 630/2497 [00:36<01:46, 17.45it/s]\u001b[A\n",
            " 25%|██▌       | 632/2497 [00:36<01:47, 17.32it/s]\u001b[A\n",
            " 25%|██▌       | 634/2497 [00:36<01:46, 17.43it/s]\u001b[A\n",
            " 25%|██▌       | 636/2497 [00:36<01:45, 17.62it/s]\u001b[A\n",
            " 26%|██▌       | 638/2497 [00:36<01:47, 17.37it/s]\u001b[A\n",
            " 26%|██▌       | 640/2497 [00:36<01:48, 17.12it/s]\u001b[A\n",
            " 26%|██▌       | 642/2497 [00:36<01:48, 17.11it/s]\u001b[A\n",
            " 26%|██▌       | 644/2497 [00:36<01:47, 17.17it/s]\u001b[A\n",
            " 26%|██▌       | 646/2497 [00:36<01:48, 16.99it/s]\u001b[A\n",
            " 26%|██▌       | 648/2497 [00:37<01:49, 16.94it/s]\u001b[A\n",
            " 26%|██▌       | 650/2497 [00:37<01:47, 17.11it/s]\u001b[A\n",
            " 26%|██▌       | 652/2497 [00:37<01:45, 17.42it/s]\u001b[A\n",
            " 26%|██▌       | 654/2497 [00:37<01:48, 16.98it/s]\u001b[A\n",
            " 26%|██▋       | 656/2497 [00:37<01:49, 16.80it/s]\u001b[A\n",
            " 26%|██▋       | 658/2497 [00:37<01:48, 16.97it/s]\u001b[A\n",
            " 26%|██▋       | 660/2497 [00:37<01:48, 17.00it/s]\u001b[A\n",
            " 27%|██▋       | 662/2497 [00:37<01:47, 17.01it/s]\u001b[A\n",
            " 27%|██▋       | 664/2497 [00:38<01:46, 17.29it/s]\u001b[A\n",
            " 27%|██▋       | 666/2497 [00:38<01:44, 17.52it/s]\u001b[A\n",
            " 27%|██▋       | 668/2497 [00:38<01:45, 17.38it/s]\u001b[A\n",
            " 27%|██▋       | 670/2497 [00:38<01:46, 17.21it/s]\u001b[A\n",
            " 27%|██▋       | 672/2497 [00:38<01:48, 16.84it/s]\u001b[A\n",
            " 27%|██▋       | 674/2497 [00:38<01:46, 17.17it/s]\u001b[A\n",
            " 27%|██▋       | 676/2497 [00:38<01:45, 17.22it/s]\u001b[A\n",
            " 27%|██▋       | 678/2497 [00:38<01:45, 17.25it/s]\u001b[A\n",
            " 27%|██▋       | 680/2497 [00:38<01:44, 17.45it/s]\u001b[A\n",
            " 27%|██▋       | 682/2497 [00:39<01:46, 17.06it/s]\u001b[A\n",
            " 27%|██▋       | 684/2497 [00:39<01:46, 17.07it/s]\u001b[A\n",
            " 27%|██▋       | 686/2497 [00:39<01:45, 17.16it/s]\u001b[A\n",
            " 28%|██▊       | 688/2497 [00:39<01:44, 17.28it/s]\u001b[A\n",
            " 28%|██▊       | 690/2497 [00:39<01:45, 17.12it/s]\u001b[A\n",
            " 28%|██▊       | 692/2497 [00:39<01:46, 16.90it/s]\u001b[A\n",
            " 28%|██▊       | 694/2497 [00:39<01:46, 16.95it/s]\u001b[A\n",
            " 28%|██▊       | 696/2497 [00:39<01:46, 16.95it/s]\u001b[A\n",
            " 28%|██▊       | 698/2497 [00:40<01:46, 16.96it/s]\u001b[A\n",
            " 28%|██▊       | 700/2497 [00:40<01:44, 17.18it/s]\u001b[A\n",
            " 28%|██▊       | 702/2497 [00:40<01:45, 17.09it/s]\u001b[A\n",
            " 28%|██▊       | 704/2497 [00:40<01:44, 17.16it/s]\u001b[A\n",
            " 28%|██▊       | 706/2497 [00:40<01:46, 16.84it/s]\u001b[A\n",
            " 28%|██▊       | 708/2497 [00:40<01:45, 16.89it/s]\u001b[A\n",
            " 28%|██▊       | 710/2497 [00:40<01:43, 17.19it/s]\u001b[A\n",
            " 29%|██▊       | 712/2497 [00:40<01:43, 17.27it/s]\u001b[A\n",
            " 29%|██▊       | 714/2497 [00:40<01:42, 17.32it/s]\u001b[A\n",
            " 29%|██▊       | 716/2497 [00:41<01:43, 17.25it/s]\u001b[A\n",
            " 29%|██▉       | 718/2497 [00:41<01:42, 17.39it/s]\u001b[A\n",
            " 29%|██▉       | 720/2497 [00:41<01:43, 17.09it/s]\u001b[A\n",
            " 29%|██▉       | 722/2497 [00:41<01:43, 17.17it/s]\u001b[A\n",
            " 29%|██▉       | 724/2497 [00:41<01:45, 16.85it/s]\u001b[A\n",
            " 29%|██▉       | 726/2497 [00:41<01:43, 17.19it/s]\u001b[A\n",
            " 29%|██▉       | 728/2497 [00:41<01:42, 17.30it/s]\u001b[A\n",
            " 29%|██▉       | 730/2497 [00:41<01:42, 17.18it/s]\u001b[A\n",
            " 29%|██▉       | 732/2497 [00:41<01:42, 17.25it/s]\u001b[A\n",
            " 29%|██▉       | 734/2497 [00:42<01:41, 17.36it/s]\u001b[A\n",
            " 29%|██▉       | 736/2497 [00:42<01:41, 17.42it/s]\u001b[A\n",
            " 30%|██▉       | 738/2497 [00:42<01:39, 17.65it/s]\u001b[A\n",
            " 30%|██▉       | 740/2497 [00:42<01:39, 17.65it/s]\u001b[A\n",
            " 30%|██▉       | 742/2497 [00:42<01:44, 16.79it/s]\u001b[A\n",
            " 30%|██▉       | 744/2497 [00:42<01:42, 17.08it/s]\u001b[A\n",
            " 30%|██▉       | 746/2497 [00:42<01:42, 17.16it/s]\u001b[A\n",
            " 30%|██▉       | 748/2497 [00:42<01:41, 17.24it/s]\u001b[A\n",
            " 30%|███       | 750/2497 [00:43<01:42, 17.10it/s]\u001b[A\n",
            " 30%|███       | 752/2497 [00:43<01:41, 17.20it/s]\u001b[A\n",
            " 30%|███       | 754/2497 [00:43<01:42, 17.08it/s]\u001b[A\n",
            " 30%|███       | 756/2497 [00:43<01:41, 17.14it/s]\u001b[A\n",
            " 30%|███       | 758/2497 [00:43<01:42, 16.96it/s]\u001b[A\n",
            " 30%|███       | 760/2497 [00:43<01:41, 17.19it/s]\u001b[A\n",
            " 31%|███       | 762/2497 [00:43<01:39, 17.36it/s]\u001b[A\n",
            " 31%|███       | 764/2497 [00:43<01:41, 17.14it/s]\u001b[A\n",
            " 31%|███       | 766/2497 [00:43<01:41, 17.02it/s]\u001b[A\n",
            " 31%|███       | 768/2497 [00:44<01:43, 16.71it/s]\u001b[A\n",
            " 31%|███       | 770/2497 [00:44<01:41, 16.95it/s]\u001b[A\n",
            " 31%|███       | 772/2497 [00:44<01:40, 17.16it/s]\u001b[A\n",
            " 31%|███       | 774/2497 [00:44<01:40, 17.17it/s]\u001b[A\n",
            " 31%|███       | 776/2497 [00:44<01:40, 17.10it/s]\u001b[A\n",
            " 31%|███       | 778/2497 [00:44<01:40, 17.04it/s]\u001b[A\n",
            " 31%|███       | 780/2497 [00:44<01:39, 17.23it/s]\u001b[A\n",
            " 31%|███▏      | 782/2497 [00:44<01:37, 17.55it/s]\u001b[A\n",
            " 31%|███▏      | 784/2497 [00:45<01:39, 17.30it/s]\u001b[A\n",
            " 31%|███▏      | 786/2497 [00:45<01:38, 17.33it/s]\u001b[A\n",
            " 32%|███▏      | 788/2497 [00:45<01:37, 17.61it/s]\u001b[A\n",
            " 32%|███▏      | 790/2497 [00:45<01:36, 17.69it/s]\u001b[A\n",
            " 32%|███▏      | 792/2497 [00:45<01:36, 17.60it/s]\u001b[A\n",
            " 32%|███▏      | 794/2497 [00:45<01:39, 17.20it/s]\u001b[A\n",
            " 32%|███▏      | 796/2497 [00:45<01:38, 17.32it/s]\u001b[A\n",
            " 32%|███▏      | 798/2497 [00:45<01:37, 17.49it/s]\u001b[A\n",
            " 32%|███▏      | 800/2497 [00:45<01:36, 17.53it/s]\u001b[A\n",
            " 32%|███▏      | 802/2497 [00:46<01:35, 17.69it/s]\u001b[A\n",
            " 32%|███▏      | 804/2497 [00:46<01:35, 17.67it/s]\u001b[A\n",
            " 32%|███▏      | 806/2497 [00:46<01:36, 17.55it/s]\u001b[A\n",
            " 32%|███▏      | 808/2497 [00:46<01:36, 17.47it/s]\u001b[A\n",
            " 32%|███▏      | 810/2497 [00:46<01:37, 17.38it/s]\u001b[A\n",
            " 33%|███▎      | 812/2497 [00:46<01:37, 17.29it/s]\u001b[A\n",
            " 33%|███▎      | 814/2497 [00:46<01:37, 17.34it/s]\u001b[A\n",
            " 33%|███▎      | 816/2497 [00:46<01:36, 17.35it/s]\u001b[A\n",
            " 33%|███▎      | 818/2497 [00:46<01:36, 17.41it/s]\u001b[A\n",
            " 33%|███▎      | 820/2497 [00:47<01:36, 17.30it/s]\u001b[A\n",
            " 33%|███▎      | 822/2497 [00:47<01:36, 17.43it/s]\u001b[A\n",
            " 33%|███▎      | 824/2497 [00:47<01:35, 17.56it/s]\u001b[A\n",
            " 33%|███▎      | 826/2497 [00:47<01:36, 17.37it/s]\u001b[A\n",
            " 33%|███▎      | 828/2497 [00:47<01:36, 17.38it/s]\u001b[A\n",
            " 33%|███▎      | 830/2497 [00:47<01:38, 16.92it/s]\u001b[A\n",
            " 33%|███▎      | 832/2497 [00:47<01:36, 17.26it/s]\u001b[A\n",
            " 33%|███▎      | 834/2497 [00:47<01:36, 17.21it/s]\u001b[A\n",
            " 33%|███▎      | 836/2497 [00:48<01:38, 16.86it/s]\u001b[A\n",
            " 34%|███▎      | 838/2497 [00:48<01:37, 17.00it/s]\u001b[A\n",
            " 34%|███▎      | 840/2497 [00:48<01:36, 17.16it/s]\u001b[A\n",
            " 34%|███▎      | 842/2497 [00:48<01:35, 17.24it/s]\u001b[A\n",
            " 34%|███▍      | 844/2497 [00:48<01:36, 17.16it/s]\u001b[A\n",
            " 34%|███▍      | 846/2497 [00:48<01:38, 16.80it/s]\u001b[A\n",
            " 34%|███▍      | 848/2497 [00:48<01:36, 17.07it/s]\u001b[A\n",
            " 34%|███▍      | 850/2497 [00:48<01:35, 17.33it/s]\u001b[A\n",
            " 34%|███▍      | 852/2497 [00:48<01:33, 17.52it/s]\u001b[A\n",
            " 34%|███▍      | 854/2497 [00:49<01:33, 17.51it/s]\u001b[A\n",
            " 34%|███▍      | 856/2497 [00:49<01:34, 17.45it/s]\u001b[A\n",
            " 34%|███▍      | 858/2497 [00:49<01:32, 17.64it/s]\u001b[A\n",
            " 34%|███▍      | 860/2497 [00:49<01:32, 17.74it/s]\u001b[A\n",
            " 35%|███▍      | 862/2497 [00:49<01:33, 17.43it/s]\u001b[A\n",
            " 35%|███▍      | 864/2497 [00:49<01:34, 17.29it/s]\u001b[A\n",
            " 35%|███▍      | 866/2497 [00:49<01:34, 17.23it/s]\u001b[A\n",
            " 35%|███▍      | 868/2497 [00:49<01:34, 17.20it/s]\u001b[A\n",
            " 35%|███▍      | 870/2497 [00:49<01:34, 17.24it/s]\u001b[A\n",
            " 35%|███▍      | 872/2497 [00:50<01:34, 17.20it/s]\u001b[A\n",
            " 35%|███▌      | 874/2497 [00:50<01:34, 17.11it/s]\u001b[A\n",
            " 35%|███▌      | 876/2497 [00:50<01:36, 16.74it/s]\u001b[A\n",
            " 35%|███▌      | 878/2497 [00:50<01:36, 16.71it/s]\u001b[A\n",
            " 35%|███▌      | 880/2497 [00:50<01:35, 16.92it/s]\u001b[A\n",
            " 35%|███▌      | 882/2497 [00:50<01:36, 16.81it/s]\u001b[A\n",
            " 35%|███▌      | 884/2497 [00:50<01:39, 16.15it/s]\u001b[A\n",
            " 35%|███▌      | 886/2497 [00:50<01:37, 16.47it/s]\u001b[A\n",
            " 36%|███▌      | 888/2497 [00:51<01:35, 16.87it/s]\u001b[A\n",
            " 36%|███▌      | 890/2497 [00:51<01:34, 16.98it/s]\u001b[A\n",
            " 36%|███▌      | 892/2497 [00:51<01:33, 17.23it/s]\u001b[A\n",
            " 36%|███▌      | 894/2497 [00:51<01:33, 17.21it/s]\u001b[A\n",
            " 36%|███▌      | 896/2497 [00:51<01:34, 16.89it/s]\u001b[A\n",
            " 36%|███▌      | 898/2497 [00:51<01:36, 16.58it/s]\u001b[A\n",
            " 36%|███▌      | 900/2497 [00:51<01:35, 16.81it/s]\u001b[A\n",
            " 36%|███▌      | 902/2497 [00:51<01:36, 16.48it/s]\u001b[A\n",
            " 36%|███▌      | 904/2497 [00:52<01:37, 16.34it/s]\u001b[A\n",
            " 36%|███▋      | 906/2497 [00:52<01:38, 16.19it/s]\u001b[A\n",
            " 36%|███▋      | 908/2497 [00:52<01:35, 16.57it/s]\u001b[A\n",
            " 36%|███▋      | 910/2497 [00:52<01:33, 16.94it/s]\u001b[A\n",
            " 37%|███▋      | 912/2497 [00:52<01:34, 16.74it/s]\u001b[A\n",
            " 37%|███▋      | 914/2497 [00:52<01:34, 16.75it/s]\u001b[A\n",
            " 37%|███▋      | 916/2497 [00:52<01:34, 16.74it/s]\u001b[A\n",
            " 37%|███▋      | 918/2497 [00:52<01:34, 16.73it/s]\u001b[A\n",
            " 37%|███▋      | 920/2497 [00:52<01:34, 16.72it/s]\u001b[A\n",
            " 37%|███▋      | 922/2497 [00:53<01:35, 16.52it/s]\u001b[A\n",
            " 37%|███▋      | 924/2497 [00:53<01:34, 16.69it/s]\u001b[A\n",
            " 37%|███▋      | 926/2497 [00:53<01:33, 16.74it/s]\u001b[A\n",
            " 37%|███▋      | 928/2497 [00:53<01:32, 16.98it/s]\u001b[A\n",
            " 37%|███▋      | 930/2497 [00:53<01:32, 16.96it/s]\u001b[A\n",
            " 37%|███▋      | 932/2497 [00:53<01:32, 16.84it/s]\u001b[A\n",
            " 37%|███▋      | 934/2497 [00:53<01:32, 16.85it/s]\u001b[A\n",
            " 37%|███▋      | 936/2497 [00:53<01:32, 16.96it/s]\u001b[A\n",
            " 38%|███▊      | 938/2497 [00:54<01:31, 17.06it/s]\u001b[A\n",
            " 38%|███▊      | 940/2497 [00:54<01:32, 16.77it/s]\u001b[A\n",
            " 38%|███▊      | 942/2497 [00:54<01:33, 16.61it/s]\u001b[A\n",
            " 38%|███▊      | 944/2497 [00:54<01:32, 16.87it/s]\u001b[A\n",
            " 38%|███▊      | 946/2497 [00:54<01:35, 16.21it/s]\u001b[A\n",
            " 38%|███▊      | 948/2497 [00:54<01:35, 16.25it/s]\u001b[A\n",
            " 38%|███▊      | 950/2497 [00:54<01:34, 16.42it/s]\u001b[A\n",
            " 38%|███▊      | 952/2497 [00:54<01:33, 16.58it/s]\u001b[A\n",
            " 38%|███▊      | 954/2497 [00:54<01:31, 16.79it/s]\u001b[A\n",
            " 38%|███▊      | 956/2497 [00:55<01:30, 16.94it/s]\u001b[A\n",
            " 38%|███▊      | 958/2497 [00:55<01:31, 16.77it/s]\u001b[A\n",
            " 38%|███▊      | 960/2497 [00:55<01:32, 16.62it/s]\u001b[A\n",
            " 39%|███▊      | 962/2497 [00:55<01:31, 16.82it/s]\u001b[A\n",
            " 39%|███▊      | 964/2497 [00:55<01:31, 16.78it/s]\u001b[A\n",
            " 39%|███▊      | 966/2497 [00:55<01:33, 16.46it/s]\u001b[A\n",
            " 39%|███▉      | 968/2497 [00:55<01:32, 16.61it/s]\u001b[A\n",
            " 39%|███▉      | 970/2497 [00:55<01:31, 16.72it/s]\u001b[A\n",
            " 39%|███▉      | 972/2497 [00:56<01:31, 16.61it/s]\u001b[A\n",
            " 39%|███▉      | 974/2497 [00:56<01:32, 16.55it/s]\u001b[A\n",
            " 39%|███▉      | 976/2497 [00:56<01:30, 16.77it/s]\u001b[A\n",
            " 39%|███▉      | 978/2497 [00:56<01:30, 16.72it/s]\u001b[A\n",
            " 39%|███▉      | 980/2497 [00:56<01:29, 16.88it/s]\u001b[A\n",
            " 39%|███▉      | 982/2497 [00:56<01:30, 16.78it/s]\u001b[A\n",
            " 39%|███▉      | 984/2497 [00:56<01:30, 16.70it/s]\u001b[A\n",
            " 39%|███▉      | 986/2497 [00:56<01:30, 16.70it/s]\u001b[A\n",
            " 40%|███▉      | 988/2497 [00:57<01:29, 16.83it/s]\u001b[A\n",
            " 40%|███▉      | 990/2497 [00:57<01:28, 16.95it/s]\u001b[A\n",
            " 40%|███▉      | 992/2497 [00:57<01:28, 17.04it/s]\u001b[A\n",
            " 40%|███▉      | 994/2497 [00:57<01:28, 16.93it/s]\u001b[A\n",
            " 40%|███▉      | 996/2497 [00:57<01:28, 17.02it/s]\u001b[A\n",
            " 40%|███▉      | 998/2497 [00:57<01:27, 17.17it/s]\u001b[A\n",
            " 40%|████      | 1000/2497 [00:57<01:29, 16.82it/s]\u001b[A\n",
            " 40%|████      | 1002/2497 [00:57<01:30, 16.58it/s]\u001b[A\n",
            " 40%|████      | 1004/2497 [00:57<01:30, 16.52it/s]\u001b[A\n",
            " 40%|████      | 1006/2497 [00:58<01:29, 16.60it/s]\u001b[A\n",
            " 40%|████      | 1008/2497 [00:58<01:29, 16.61it/s]\u001b[A\n",
            " 40%|████      | 1010/2497 [00:58<01:29, 16.62it/s]\u001b[A\n",
            " 41%|████      | 1012/2497 [00:58<01:28, 16.71it/s]\u001b[A\n",
            " 41%|████      | 1014/2497 [00:58<01:27, 16.94it/s]\u001b[A\n",
            " 41%|████      | 1016/2497 [00:58<01:29, 16.57it/s]\u001b[A\n",
            " 41%|████      | 1018/2497 [00:58<01:29, 16.58it/s]\u001b[A\n",
            " 41%|████      | 1020/2497 [00:58<01:28, 16.65it/s]\u001b[A\n",
            " 41%|████      | 1022/2497 [00:59<01:27, 16.80it/s]\u001b[A\n",
            " 41%|████      | 1024/2497 [00:59<01:28, 16.72it/s]\u001b[A\n",
            " 41%|████      | 1026/2497 [00:59<01:27, 16.75it/s]\u001b[A\n",
            " 41%|████      | 1028/2497 [00:59<01:28, 16.69it/s]\u001b[A\n",
            " 41%|████      | 1030/2497 [00:59<01:28, 16.58it/s]\u001b[A\n",
            " 41%|████▏     | 1032/2497 [00:59<01:31, 15.98it/s]\u001b[A\n",
            " 41%|████▏     | 1034/2497 [00:59<01:31, 16.05it/s]\u001b[A\n",
            " 41%|████▏     | 1036/2497 [00:59<01:30, 16.09it/s]\u001b[A\n",
            " 42%|████▏     | 1038/2497 [01:00<01:31, 16.00it/s]\u001b[A\n",
            " 42%|████▏     | 1040/2497 [01:00<01:30, 16.02it/s]\u001b[A\n",
            " 42%|████▏     | 1042/2497 [01:00<01:29, 16.30it/s]\u001b[A\n",
            " 42%|████▏     | 1044/2497 [01:00<01:28, 16.38it/s]\u001b[A\n",
            " 42%|████▏     | 1046/2497 [01:00<01:27, 16.59it/s]\u001b[A\n",
            " 42%|████▏     | 1048/2497 [01:00<01:28, 16.44it/s]\u001b[A\n",
            " 42%|████▏     | 1050/2497 [01:00<01:28, 16.33it/s]\u001b[A\n",
            " 42%|████▏     | 1052/2497 [01:00<01:28, 16.30it/s]\u001b[A\n",
            " 42%|████▏     | 1054/2497 [01:01<01:26, 16.68it/s]\u001b[A\n",
            " 42%|████▏     | 1056/2497 [01:01<01:28, 16.35it/s]\u001b[A\n",
            " 42%|████▏     | 1058/2497 [01:01<01:27, 16.41it/s]\u001b[A\n",
            " 42%|████▏     | 1060/2497 [01:01<01:26, 16.69it/s]\u001b[A\n",
            " 43%|████▎     | 1062/2497 [01:01<01:26, 16.54it/s]\u001b[A\n",
            " 43%|████▎     | 1064/2497 [01:01<01:26, 16.65it/s]\u001b[A\n",
            " 43%|████▎     | 1066/2497 [01:01<01:27, 16.31it/s]\u001b[A\n",
            " 43%|████▎     | 1068/2497 [01:01<01:26, 16.43it/s]\u001b[A\n",
            " 43%|████▎     | 1070/2497 [01:01<01:28, 16.18it/s]\u001b[A\n",
            " 43%|████▎     | 1072/2497 [01:02<01:27, 16.25it/s]\u001b[A\n",
            " 43%|████▎     | 1074/2497 [01:02<01:28, 16.06it/s]\u001b[A\n",
            " 43%|████▎     | 1076/2497 [01:02<01:27, 16.22it/s]\u001b[A\n",
            " 43%|████▎     | 1078/2497 [01:02<01:28, 16.01it/s]\u001b[A\n",
            " 43%|████▎     | 1080/2497 [01:02<01:26, 16.32it/s]\u001b[A\n",
            " 43%|████▎     | 1082/2497 [01:02<01:25, 16.60it/s]\u001b[A\n",
            " 43%|████▎     | 1084/2497 [01:02<01:25, 16.57it/s]\u001b[A\n",
            " 43%|████▎     | 1086/2497 [01:02<01:24, 16.62it/s]\u001b[A\n",
            " 44%|████▎     | 1088/2497 [01:03<01:24, 16.74it/s]\u001b[A\n",
            " 44%|████▎     | 1090/2497 [01:03<01:22, 17.05it/s]\u001b[A\n",
            " 44%|████▎     | 1092/2497 [01:03<01:22, 17.08it/s]\u001b[A\n",
            " 44%|████▍     | 1094/2497 [01:03<01:22, 16.99it/s]\u001b[A\n",
            " 44%|████▍     | 1096/2497 [01:03<01:22, 17.01it/s]\u001b[A\n",
            " 44%|████▍     | 1098/2497 [01:03<01:22, 17.04it/s]\u001b[A\n",
            " 44%|████▍     | 1100/2497 [01:03<01:24, 16.60it/s]\u001b[A\n",
            " 44%|████▍     | 1102/2497 [01:03<01:24, 16.45it/s]\u001b[A\n",
            " 44%|████▍     | 1104/2497 [01:04<01:23, 16.59it/s]\u001b[A\n",
            " 44%|████▍     | 1106/2497 [01:04<01:23, 16.73it/s]\u001b[A\n",
            " 44%|████▍     | 1108/2497 [01:04<01:22, 16.85it/s]\u001b[A\n",
            " 44%|████▍     | 1110/2497 [01:04<01:24, 16.43it/s]\u001b[A\n",
            " 45%|████▍     | 1112/2497 [01:04<01:23, 16.55it/s]\u001b[A\n",
            " 45%|████▍     | 1114/2497 [01:04<01:24, 16.42it/s]\u001b[A\n",
            " 45%|████▍     | 1116/2497 [01:04<01:22, 16.66it/s]\u001b[A\n",
            " 45%|████▍     | 1118/2497 [01:04<01:23, 16.53it/s]\u001b[A\n",
            " 45%|████▍     | 1120/2497 [01:05<01:23, 16.53it/s]\u001b[A\n",
            " 45%|████▍     | 1122/2497 [01:05<01:23, 16.43it/s]\u001b[A\n",
            " 45%|████▌     | 1124/2497 [01:05<01:21, 16.87it/s]\u001b[A\n",
            " 45%|████▌     | 1126/2497 [01:05<01:21, 16.86it/s]\u001b[A\n",
            " 45%|████▌     | 1128/2497 [01:05<01:20, 16.96it/s]\u001b[A\n",
            " 45%|████▌     | 1130/2497 [01:05<01:19, 17.10it/s]\u001b[A\n",
            " 45%|████▌     | 1132/2497 [01:05<01:20, 17.03it/s]\u001b[A\n",
            " 45%|████▌     | 1134/2497 [01:05<01:21, 16.64it/s]\u001b[A\n",
            " 45%|████▌     | 1136/2497 [01:05<01:21, 16.79it/s]\u001b[A\n",
            " 46%|████▌     | 1138/2497 [01:06<01:20, 16.93it/s]\u001b[A\n",
            " 46%|████▌     | 1140/2497 [01:06<01:21, 16.74it/s]\u001b[A\n",
            " 46%|████▌     | 1142/2497 [01:06<01:19, 17.06it/s]\u001b[A\n",
            " 46%|████▌     | 1144/2497 [01:06<01:18, 17.28it/s]\u001b[A\n",
            " 46%|████▌     | 1146/2497 [01:06<01:18, 17.19it/s]\u001b[A\n",
            " 46%|████▌     | 1148/2497 [01:06<01:20, 16.82it/s]\u001b[A\n",
            " 46%|████▌     | 1150/2497 [01:06<01:18, 17.07it/s]\u001b[A\n",
            " 46%|████▌     | 1152/2497 [01:06<01:20, 16.72it/s]\u001b[A\n",
            " 46%|████▌     | 1154/2497 [01:07<01:20, 16.67it/s]\u001b[A\n",
            " 46%|████▋     | 1156/2497 [01:07<01:19, 16.80it/s]\u001b[A\n",
            " 46%|████▋     | 1158/2497 [01:07<01:19, 16.74it/s]\u001b[A\n",
            " 46%|████▋     | 1160/2497 [01:07<01:18, 16.94it/s]\u001b[A\n",
            " 47%|████▋     | 1162/2497 [01:07<01:18, 16.94it/s]\u001b[A\n",
            " 47%|████▋     | 1164/2497 [01:07<01:18, 16.89it/s]\u001b[A\n",
            " 47%|████▋     | 1166/2497 [01:07<01:17, 17.10it/s]\u001b[A\n",
            " 47%|████▋     | 1168/2497 [01:07<01:18, 16.89it/s]\u001b[A\n",
            " 47%|████▋     | 1170/2497 [01:07<01:18, 16.84it/s]\u001b[A\n",
            " 47%|████▋     | 1172/2497 [01:08<01:17, 17.04it/s]\u001b[A\n",
            " 47%|████▋     | 1174/2497 [01:08<01:17, 17.07it/s]\u001b[A\n",
            " 47%|████▋     | 1176/2497 [01:08<01:17, 17.15it/s]\u001b[A\n",
            " 47%|████▋     | 1178/2497 [01:08<01:18, 16.72it/s]\u001b[A\n",
            " 47%|████▋     | 1180/2497 [01:08<01:18, 16.73it/s]\u001b[A\n",
            " 47%|████▋     | 1182/2497 [01:08<01:17, 16.93it/s]\u001b[A\n",
            " 47%|████▋     | 1184/2497 [01:08<01:17, 16.84it/s]\u001b[A\n",
            " 47%|████▋     | 1186/2497 [01:08<01:17, 16.84it/s]\u001b[A\n",
            " 48%|████▊     | 1188/2497 [01:09<01:17, 16.95it/s]\u001b[A\n",
            " 48%|████▊     | 1190/2497 [01:09<01:18, 16.68it/s]\u001b[A\n",
            " 48%|████▊     | 1192/2497 [01:09<01:18, 16.62it/s]\u001b[A\n",
            " 48%|████▊     | 1194/2497 [01:09<01:17, 16.87it/s]\u001b[A\n",
            " 48%|████▊     | 1196/2497 [01:09<01:16, 17.08it/s]\u001b[A\n",
            " 48%|████▊     | 1198/2497 [01:09<01:15, 17.11it/s]\u001b[A\n",
            " 48%|████▊     | 1200/2497 [01:09<01:15, 17.11it/s]\u001b[A\n",
            " 48%|████▊     | 1202/2497 [01:09<01:16, 16.88it/s]\u001b[A\n",
            " 48%|████▊     | 1204/2497 [01:09<01:15, 17.07it/s]\u001b[A\n",
            " 48%|████▊     | 1206/2497 [01:10<01:15, 17.03it/s]\u001b[A\n",
            " 48%|████▊     | 1208/2497 [01:10<01:17, 16.69it/s]\u001b[A\n",
            " 48%|████▊     | 1210/2497 [01:10<01:15, 16.94it/s]\u001b[A\n",
            " 49%|████▊     | 1212/2497 [01:10<01:15, 17.06it/s]\u001b[A\n",
            " 49%|████▊     | 1214/2497 [01:10<01:14, 17.22it/s]\u001b[A\n",
            " 49%|████▊     | 1216/2497 [01:10<01:14, 17.17it/s]\u001b[A\n",
            " 49%|████▉     | 1218/2497 [01:10<01:14, 17.27it/s]\u001b[A\n",
            " 49%|████▉     | 1220/2497 [01:10<01:15, 16.99it/s]\u001b[A\n",
            " 49%|████▉     | 1222/2497 [01:11<01:16, 16.75it/s]\u001b[A\n",
            " 49%|████▉     | 1224/2497 [01:11<01:15, 16.89it/s]\u001b[A\n",
            " 49%|████▉     | 1226/2497 [01:11<01:14, 17.03it/s]\u001b[A\n",
            " 49%|████▉     | 1228/2497 [01:11<01:14, 16.93it/s]\u001b[A\n",
            " 49%|████▉     | 1230/2497 [01:11<01:15, 16.87it/s]\u001b[A\n",
            " 49%|████▉     | 1232/2497 [01:11<01:13, 17.15it/s]\u001b[A\n",
            " 49%|████▉     | 1234/2497 [01:11<01:13, 17.12it/s]\u001b[A\n",
            " 49%|████▉     | 1236/2497 [01:11<01:13, 17.18it/s]\u001b[A\n",
            " 50%|████▉     | 1238/2497 [01:11<01:15, 16.77it/s]\u001b[A\n",
            " 50%|████▉     | 1240/2497 [01:12<01:15, 16.61it/s]\u001b[A\n",
            " 50%|████▉     | 1242/2497 [01:12<01:15, 16.57it/s]\u001b[A\n",
            " 50%|████▉     | 1244/2497 [01:12<01:13, 16.95it/s]\u001b[A\n",
            " 50%|████▉     | 1246/2497 [01:12<01:13, 17.08it/s]\u001b[A\n",
            " 50%|████▉     | 1248/2497 [01:12<01:13, 17.04it/s]\u001b[A\n",
            " 50%|█████     | 1250/2497 [01:12<01:12, 17.14it/s]\u001b[A\n",
            " 50%|█████     | 1252/2497 [01:12<01:12, 17.25it/s]\u001b[A\n",
            " 50%|█████     | 1254/2497 [01:12<01:13, 16.85it/s]\u001b[A\n",
            " 50%|█████     | 1256/2497 [01:13<01:13, 16.95it/s]\u001b[A\n",
            " 50%|█████     | 1258/2497 [01:13<01:12, 17.17it/s]\u001b[A\n",
            " 50%|█████     | 1260/2497 [01:13<01:12, 17.10it/s]\u001b[A\n",
            " 51%|█████     | 1262/2497 [01:13<01:13, 16.83it/s]\u001b[A\n",
            " 51%|█████     | 1264/2497 [01:13<01:12, 16.99it/s]\u001b[A\n",
            " 51%|█████     | 1266/2497 [01:13<01:11, 17.12it/s]\u001b[A\n",
            " 51%|█████     | 1268/2497 [01:13<01:12, 16.85it/s]\u001b[A\n",
            " 51%|█████     | 1270/2497 [01:13<01:12, 16.93it/s]\u001b[A\n",
            " 51%|█████     | 1272/2497 [01:13<01:14, 16.50it/s]\u001b[A\n",
            " 51%|█████     | 1274/2497 [01:14<01:13, 16.66it/s]\u001b[A\n",
            " 51%|█████     | 1276/2497 [01:14<01:12, 16.75it/s]\u001b[A\n",
            " 51%|█████     | 1278/2497 [01:14<01:11, 16.99it/s]\u001b[A\n",
            " 51%|█████▏    | 1280/2497 [01:14<01:12, 16.86it/s]\u001b[A\n",
            " 51%|█████▏    | 1282/2497 [01:14<01:11, 17.02it/s]\u001b[A\n",
            " 51%|█████▏    | 1284/2497 [01:14<01:11, 16.87it/s]\u001b[A\n",
            " 52%|█████▏    | 1286/2497 [01:14<01:11, 16.90it/s]\u001b[A\n",
            " 52%|█████▏    | 1288/2497 [01:14<01:11, 16.98it/s]\u001b[A\n",
            " 52%|█████▏    | 1290/2497 [01:15<01:10, 17.22it/s]\u001b[A\n",
            " 52%|█████▏    | 1292/2497 [01:15<01:10, 17.09it/s]\u001b[A\n",
            " 52%|█████▏    | 1294/2497 [01:15<01:10, 17.12it/s]\u001b[A\n",
            " 52%|█████▏    | 1296/2497 [01:15<01:09, 17.16it/s]\u001b[A\n",
            " 52%|█████▏    | 1298/2497 [01:15<01:11, 16.87it/s]\u001b[A\n",
            " 52%|█████▏    | 1300/2497 [01:15<01:11, 16.84it/s]\u001b[A\n",
            " 52%|█████▏    | 1302/2497 [01:15<01:10, 16.99it/s]\u001b[A\n",
            " 52%|█████▏    | 1304/2497 [01:15<01:13, 16.32it/s]\u001b[A\n",
            " 52%|█████▏    | 1306/2497 [01:16<01:13, 16.22it/s]\u001b[A\n",
            " 52%|█████▏    | 1308/2497 [01:16<01:12, 16.46it/s]\u001b[A\n",
            " 52%|█████▏    | 1310/2497 [01:16<01:12, 16.46it/s]\u001b[A\n",
            " 53%|█████▎    | 1312/2497 [01:16<01:10, 16.72it/s]\u001b[A\n",
            " 53%|█████▎    | 1314/2497 [01:16<01:10, 16.73it/s]\u001b[A\n",
            " 53%|█████▎    | 1316/2497 [01:16<01:10, 16.70it/s]\u001b[A\n",
            " 53%|█████▎    | 1318/2497 [01:16<01:09, 16.85it/s]\u001b[A\n",
            " 53%|█████▎    | 1320/2497 [01:16<01:09, 16.90it/s]\u001b[A\n",
            " 53%|█████▎    | 1322/2497 [01:16<01:10, 16.72it/s]\u001b[A\n",
            " 53%|█████▎    | 1324/2497 [01:17<01:08, 17.01it/s]\u001b[A\n",
            " 53%|█████▎    | 1326/2497 [01:17<01:10, 16.64it/s]\u001b[A\n",
            " 53%|█████▎    | 1328/2497 [01:17<01:10, 16.69it/s]\u001b[A\n",
            " 53%|█████▎    | 1330/2497 [01:17<01:11, 16.29it/s]\u001b[A\n",
            " 53%|█████▎    | 1332/2497 [01:17<01:11, 16.25it/s]\u001b[A\n",
            " 53%|█████▎    | 1334/2497 [01:17<01:09, 16.67it/s]\u001b[A\n",
            " 54%|█████▎    | 1336/2497 [01:17<01:09, 16.75it/s]\u001b[A\n",
            " 54%|█████▎    | 1338/2497 [01:17<01:09, 16.59it/s]\u001b[A\n",
            " 54%|█████▎    | 1340/2497 [01:18<01:10, 16.36it/s]\u001b[A\n",
            " 54%|█████▎    | 1342/2497 [01:18<01:09, 16.59it/s]\u001b[A\n",
            " 54%|█████▍    | 1344/2497 [01:18<01:09, 16.54it/s]\u001b[A\n",
            " 54%|█████▍    | 1346/2497 [01:18<01:08, 16.76it/s]\u001b[A\n",
            " 54%|█████▍    | 1348/2497 [01:18<01:08, 16.88it/s]\u001b[A\n",
            " 54%|█████▍    | 1350/2497 [01:18<01:09, 16.56it/s]\u001b[A\n",
            " 54%|█████▍    | 1352/2497 [01:18<01:09, 16.43it/s]\u001b[A\n",
            " 54%|█████▍    | 1354/2497 [01:18<01:08, 16.59it/s]\u001b[A\n",
            " 54%|█████▍    | 1356/2497 [01:19<01:09, 16.33it/s]\u001b[A\n",
            " 54%|█████▍    | 1358/2497 [01:19<01:10, 16.23it/s]\u001b[A\n",
            " 54%|█████▍    | 1360/2497 [01:19<01:09, 16.40it/s]\u001b[A\n",
            " 55%|█████▍    | 1362/2497 [01:19<01:07, 16.74it/s]\u001b[A\n",
            " 55%|█████▍    | 1364/2497 [01:19<01:08, 16.48it/s]\u001b[A\n",
            " 55%|█████▍    | 1366/2497 [01:19<01:08, 16.50it/s]\u001b[A\n",
            " 55%|█████▍    | 1368/2497 [01:19<01:08, 16.58it/s]\u001b[A\n",
            " 55%|█████▍    | 1370/2497 [01:19<01:07, 16.63it/s]\u001b[A\n",
            " 55%|█████▍    | 1372/2497 [01:19<01:07, 16.55it/s]\u001b[A\n",
            " 55%|█████▌    | 1374/2497 [01:20<01:08, 16.38it/s]\u001b[A\n",
            " 55%|█████▌    | 1376/2497 [01:20<01:07, 16.49it/s]\u001b[A\n",
            " 55%|█████▌    | 1378/2497 [01:20<01:06, 16.71it/s]\u001b[A\n",
            " 55%|█████▌    | 1380/2497 [01:20<01:06, 16.79it/s]\u001b[A\n",
            " 55%|█████▌    | 1382/2497 [01:20<01:06, 16.83it/s]\u001b[A\n",
            " 55%|█████▌    | 1384/2497 [01:20<01:05, 16.93it/s]\u001b[A\n",
            " 56%|█████▌    | 1386/2497 [01:20<01:05, 16.93it/s]\u001b[A\n",
            " 56%|█████▌    | 1388/2497 [01:20<01:05, 17.04it/s]\u001b[A\n",
            " 56%|█████▌    | 1390/2497 [01:21<01:06, 16.58it/s]\u001b[A\n",
            " 56%|█████▌    | 1392/2497 [01:21<01:05, 16.92it/s]\u001b[A\n",
            " 56%|█████▌    | 1394/2497 [01:21<01:05, 16.82it/s]\u001b[A\n",
            " 56%|█████▌    | 1396/2497 [01:21<01:05, 16.78it/s]\u001b[A\n",
            " 56%|█████▌    | 1398/2497 [01:21<01:05, 16.66it/s]\u001b[A\n",
            " 56%|█████▌    | 1400/2497 [01:21<01:05, 16.71it/s]\u001b[A\n",
            " 56%|█████▌    | 1402/2497 [01:21<01:04, 16.90it/s]\u001b[A\n",
            " 56%|█████▌    | 1404/2497 [01:21<01:05, 16.76it/s]\u001b[A\n",
            " 56%|█████▋    | 1406/2497 [01:22<01:06, 16.52it/s]\u001b[A\n",
            " 56%|█████▋    | 1408/2497 [01:22<01:05, 16.62it/s]\u001b[A\n",
            " 56%|█████▋    | 1410/2497 [01:22<01:05, 16.63it/s]\u001b[A\n",
            " 57%|█████▋    | 1412/2497 [01:22<01:04, 16.90it/s]\u001b[A\n",
            " 57%|█████▋    | 1414/2497 [01:22<01:04, 16.72it/s]\u001b[A\n",
            " 57%|█████▋    | 1416/2497 [01:22<01:04, 16.67it/s]\u001b[A\n",
            " 57%|█████▋    | 1418/2497 [01:22<01:04, 16.76it/s]\u001b[A\n",
            " 57%|█████▋    | 1420/2497 [01:22<01:04, 16.74it/s]\u001b[A\n",
            " 57%|█████▋    | 1422/2497 [01:22<01:03, 16.91it/s]\u001b[A\n",
            " 57%|█████▋    | 1424/2497 [01:23<01:04, 16.66it/s]\u001b[A\n",
            " 57%|█████▋    | 1426/2497 [01:23<01:03, 16.88it/s]\u001b[A\n",
            " 57%|█████▋    | 1428/2497 [01:23<01:04, 16.53it/s]\u001b[A\n",
            " 57%|█████▋    | 1430/2497 [01:23<01:03, 16.87it/s]\u001b[A\n",
            " 57%|█████▋    | 1432/2497 [01:23<01:03, 16.87it/s]\u001b[A\n",
            " 57%|█████▋    | 1434/2497 [01:23<01:03, 16.77it/s]\u001b[A\n",
            " 58%|█████▊    | 1436/2497 [01:23<01:03, 16.80it/s]\u001b[A\n",
            " 58%|█████▊    | 1438/2497 [01:23<01:04, 16.52it/s]\u001b[A\n",
            " 58%|█████▊    | 1440/2497 [01:24<01:04, 16.43it/s]\u001b[A\n",
            " 58%|█████▊    | 1442/2497 [01:24<01:03, 16.65it/s]\u001b[A\n",
            " 58%|█████▊    | 1444/2497 [01:24<01:02, 16.82it/s]\u001b[A\n",
            " 58%|█████▊    | 1446/2497 [01:24<01:03, 16.62it/s]\u001b[A\n",
            " 58%|█████▊    | 1448/2497 [01:24<01:03, 16.51it/s]\u001b[A\n",
            " 58%|█████▊    | 1450/2497 [01:24<01:02, 16.70it/s]\u001b[A\n",
            " 58%|█████▊    | 1452/2497 [01:24<01:01, 16.87it/s]\u001b[A\n",
            " 58%|█████▊    | 1454/2497 [01:24<01:03, 16.55it/s]\u001b[A\n",
            " 58%|█████▊    | 1456/2497 [01:24<01:03, 16.50it/s]\u001b[A\n",
            " 58%|█████▊    | 1458/2497 [01:25<01:02, 16.66it/s]\u001b[A\n",
            " 58%|█████▊    | 1460/2497 [01:25<01:02, 16.68it/s]\u001b[A\n",
            " 59%|█████▊    | 1462/2497 [01:25<01:02, 16.56it/s]\u001b[A\n",
            " 59%|█████▊    | 1464/2497 [01:25<01:01, 16.71it/s]\u001b[A\n",
            " 59%|█████▊    | 1466/2497 [01:25<01:01, 16.87it/s]\u001b[A\n",
            " 59%|█████▉    | 1468/2497 [01:25<01:00, 17.13it/s]\u001b[A\n",
            " 59%|█████▉    | 1470/2497 [01:25<01:01, 16.68it/s]\u001b[A\n",
            " 59%|█████▉    | 1472/2497 [01:25<01:00, 16.86it/s]\u001b[A\n",
            " 59%|█████▉    | 1474/2497 [01:26<01:01, 16.55it/s]\u001b[A\n",
            " 59%|█████▉    | 1476/2497 [01:26<01:00, 16.81it/s]\u001b[A\n",
            " 59%|█████▉    | 1478/2497 [01:26<01:00, 16.88it/s]\u001b[A\n",
            " 59%|█████▉    | 1480/2497 [01:26<01:00, 16.81it/s]\u001b[A\n",
            " 59%|█████▉    | 1482/2497 [01:26<01:01, 16.49it/s]\u001b[A\n",
            " 59%|█████▉    | 1484/2497 [01:26<01:01, 16.59it/s]\u001b[A\n",
            " 60%|█████▉    | 1486/2497 [01:26<01:01, 16.53it/s]\u001b[A\n",
            " 60%|█████▉    | 1488/2497 [01:26<01:00, 16.62it/s]\u001b[A\n",
            " 60%|█████▉    | 1490/2497 [01:27<01:00, 16.59it/s]\u001b[A\n",
            " 60%|█████▉    | 1492/2497 [01:27<01:01, 16.39it/s]\u001b[A\n",
            " 60%|█████▉    | 1494/2497 [01:27<01:00, 16.51it/s]\u001b[A\n",
            " 60%|█████▉    | 1496/2497 [01:27<01:01, 16.34it/s]\u001b[A\n",
            " 60%|█████▉    | 1498/2497 [01:27<01:00, 16.40it/s]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v21I_EXq7ruw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b85fb9b6-7ea7-43c1-95e0-5c670895a2ed"
      },
      "source": [
        "X=[]\n",
        "Y=[]\n",
        "j=0\n",
        "for file in tqdm(os.listdir(ela_real)):\n",
        "    img=Image.open(ela_real+file)\n",
        "    img=np.array(img)\n",
        "    X.append(img)\n",
        "    Y.append(0)\n",
        "    j+=1\n",
        "    if(j==1500):\n",
        "        break\n",
        "j=0\n",
        "for file in tqdm(os.listdir(ela_fake)):\n",
        "    img=Image.open(ela_fake+file)\n",
        "    img=np.array(img)\n",
        "    X.append(img)\n",
        "    Y.append(1)\n",
        "    j+=1\n",
        "    if(j==1500):\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/1500 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 102/1500 [00:00<00:01, 1011.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 195/1500 [00:00<00:01, 984.45it/s] \u001b[A\u001b[A\n",
            "\n",
            " 19%|█▉        | 292/1500 [00:00<00:01, 977.76it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 385/1500 [00:00<00:01, 961.42it/s]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 478/1500 [00:00<00:01, 951.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 574/1500 [00:00<00:00, 951.70it/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 672/1500 [00:00<00:00, 957.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 765/1500 [00:00<00:00, 947.72it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 860/1500 [00:00<00:00, 946.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▎   | 956/1500 [00:01<00:00, 948.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 1052/1500 [00:01<00:00, 948.84it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 1152/1500 [00:01<00:00, 960.94it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 1247/1500 [00:01<00:00, 953.78it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 1342/1500 [00:01<00:00, 948.73it/s]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▌| 1439/1500 [00:01<00:00, 913.17it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/1500 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▊         | 129/1500 [00:00<00:01, 1285.70it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 260/1500 [00:00<00:00, 1289.68it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▋       | 395/1500 [00:00<00:00, 1307.02it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 517/1500 [00:00<00:00, 1279.63it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 643/1500 [00:00<00:00, 1272.93it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 775/1500 [00:00<00:00, 1285.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 905/1500 [00:00<00:00, 1287.86it/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 1034/1500 [00:00<00:00, 1285.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 1156/1500 [00:00<00:00, 1245.79it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 1276/1500 [00:01<00:00, 1217.25it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 1399/1500 [00:01<00:00, 1175.78it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiEWceZy880x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05a325ee-0d8c-4b0c-9c9e-f4d07dcc02e1"
      },
      "source": [
        "X=np.array(X)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHyRV4SAwTfI"
      },
      "source": [
        "##**Test-Train Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGK4rVOI9N30"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "x_train, x_dev, y_train, y_dev = train_test_split(X, Y, test_size=0.2, random_state=133,shuffle=True)\n",
        "y_train=to_categorical(y_train,2)\n",
        "y_dev=to_categorical(y_dev,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyHPfFLHwYDe"
      },
      "source": [
        "#**MobileNetV2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F1oPNsD9REz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86013610-6467-418b-e6f8-44dd12e562fc"
      },
      "source": [
        "from tensorflow.keras.applications import MobileNetV2,VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization,Dropout,MaxPooling2D\n",
        "from tensorflow.keras.regularizers import l1,l2,l1_l2\n",
        "\n",
        "base_model = MobileNetV2(input_shape=(224,224,3),include_top=False,weights='imagenet')\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "x=base_model.output\n",
        "x=Conv2D(1024,(3,3),padding='same',activation='relu')(x)\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Flatten()(x)\n",
        "x=Dense(1024,activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(x)\n",
        "x=Dropout(0.3)(x)\n",
        "x=Dense(16,activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(x)\n",
        "x=Dense(2,activation='softmax')(x)\n",
        "model=Model(base_model.input,x)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwfv8YpPwsFp"
      },
      "source": [
        "##**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv9WJE7qtNth",
        "outputId": "af0e6871-0e8b-4cb1-ab3f-11ad466f9e8f"
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
            "                                                                 block_2_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
            "                                                                 block_4_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
            "                                                                 block_5_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
            "                                                                 block_7_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
            "                                                                 block_8_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
            "                                                                 block_9_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
            "                                                                 block_11_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
            "                                                                 block_12_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
            "                                                                 block_14_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
            "                                                                 block_15_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 7, 7, 1024)   11797504    out_relu[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 1024)         0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1024)         0           global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         1049600     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 16)           16400       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2)            34          dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 15,121,522\n",
            "Trainable params: 12,863,538\n",
            "Non-trainable params: 2,257,984\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDTzGE9Kd_sS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSaAKSm_9ZXG"
      },
      "source": [
        "epochs = 100\n",
        "batch_size = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH1VlVmKwxGC"
      },
      "source": [
        "##**Early Stopping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILu6GR5i9qxF"
      },
      "source": [
        "import keras\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=13,verbose=1,restore_best_weights=True)\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.22, patience = 6, verbose = 1, \n",
        "                                              min_delta = 0.0001,min_lr=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dfl9FPio9w8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb1c915f-034e-4a53-b13d-b53f01c58060"
      },
      "source": [
        "hist = model.fit(x_train,y_train,\n",
        "                 epochs = epochs,\n",
        "                validation_data = (x_dev,y_dev),\n",
        "                callbacks = [early_stop,reduce_lr],\n",
        "                verbose=1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 60%|█████▉    | 1498/2497 [01:40<01:00, 16.40it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "75/75 [==============================] - 42s 90ms/step - loss: 7.5772 - accuracy: 0.7366 - val_loss: 2.4766 - val_accuracy: 0.7917\n",
            "Epoch 2/100\n",
            "75/75 [==============================] - 5s 67ms/step - loss: 2.1271 - accuracy: 0.7679 - val_loss: 1.4094 - val_accuracy: 0.7900\n",
            "Epoch 3/100\n",
            "75/75 [==============================] - 5s 67ms/step - loss: 1.2488 - accuracy: 0.7995 - val_loss: 0.8546 - val_accuracy: 0.7900\n",
            "Epoch 4/100\n",
            "75/75 [==============================] - 5s 67ms/step - loss: 0.7851 - accuracy: 0.7950 - val_loss: 0.6617 - val_accuracy: 0.7917\n",
            "Epoch 5/100\n",
            "75/75 [==============================] - 5s 67ms/step - loss: 0.6415 - accuracy: 0.7921 - val_loss: 0.5699 - val_accuracy: 0.7950\n",
            "Epoch 6/100\n",
            "75/75 [==============================] - 5s 67ms/step - loss: 0.5897 - accuracy: 0.7872 - val_loss: 0.5346 - val_accuracy: 0.7950\n",
            "Epoch 7/100\n",
            "75/75 [==============================] - 5s 67ms/step - loss: 0.5099 - accuracy: 0.8053 - val_loss: 0.5239 - val_accuracy: 0.7933\n",
            "Epoch 8/100\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.4976 - accuracy: 0.8040 - val_loss: 0.4989 - val_accuracy: 0.7967\n",
            "Epoch 9/100\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.4717 - accuracy: 0.8084 - val_loss: 0.4723 - val_accuracy: 0.7917\n",
            "Epoch 10/100\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.4341 - accuracy: 0.8192 - val_loss: 0.4963 - val_accuracy: 0.7833\n",
            "Epoch 11/100\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.4231 - accuracy: 0.8116 - val_loss: 0.4624 - val_accuracy: 0.8017\n",
            "Epoch 12/100\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.4062 - accuracy: 0.8179 - val_loss: 0.4732 - val_accuracy: 0.7967\n",
            "Epoch 13/100\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.3961 - accuracy: 0.8263 - val_loss: 0.4561 - val_accuracy: 0.7967\n",
            "Epoch 14/100\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.3804 - accuracy: 0.8300 - val_loss: 0.4688 - val_accuracy: 0.8017\n",
            "Epoch 15/100\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.3742 - accuracy: 0.8310 - val_loss: 0.4632 - val_accuracy: 0.8067\n",
            "Epoch 16/100\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.3791 - accuracy: 0.8285 - val_loss: 0.4708 - val_accuracy: 0.8017\n",
            "Epoch 17/100\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.3536 - accuracy: 0.8479 - val_loss: 0.4668 - val_accuracy: 0.8000\n",
            "Epoch 18/100\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.3613 - accuracy: 0.8460 - val_loss: 0.5033 - val_accuracy: 0.8083\n",
            "Epoch 19/100\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.3133 - accuracy: 0.8703 - val_loss: 0.5036 - val_accuracy: 0.7600\n",
            "Epoch 20/100\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.3075 - accuracy: 0.8789 - val_loss: 0.4958 - val_accuracy: 0.7983\n",
            "Epoch 21/100\n",
            "75/75 [==============================] - 5s 70ms/step - loss: 0.2965 - accuracy: 0.8875 - val_loss: 0.5391 - val_accuracy: 0.7783\n",
            "Epoch 22/100\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.2684 - accuracy: 0.8940 - val_loss: 0.5491 - val_accuracy: 0.7333\n",
            "Epoch 23/100\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.2607 - accuracy: 0.9031 - val_loss: 0.5888 - val_accuracy: 0.7617\n",
            "Epoch 24/100\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.2391 - accuracy: 0.9078 - val_loss: 0.7354 - val_accuracy: 0.7967\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00022000001044943928.\n",
            "Epoch 25/100\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.2041 - accuracy: 0.9259 - val_loss: 0.6945 - val_accuracy: 0.7983\n",
            "Epoch 26/100\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.1769 - accuracy: 0.9397 - val_loss: 0.7201 - val_accuracy: 0.7817\n",
            "Epoch 27/100\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.1659 - accuracy: 0.9413 - val_loss: 0.7176 - val_accuracy: 0.7917\n",
            "Epoch 28/100\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.1528 - accuracy: 0.9503 - val_loss: 0.7915 - val_accuracy: 0.7633\n",
            "Epoch 29/100\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.1317 - accuracy: 0.9631 - val_loss: 0.8090 - val_accuracy: 0.7933\n",
            "Epoch 30/100\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.1304 - accuracy: 0.9610 - val_loss: 0.8712 - val_accuracy: 0.7583\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "Epoch 31/100\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.1233 - accuracy: 0.9642 - val_loss: 0.8481 - val_accuracy: 0.7800\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vfY5m5lw-aD"
      },
      "source": [
        "##**Loss and accuracy plots for training and validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP4rPLBg91bS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e57ee67d-70ce-428f-99e1-276d7dc7555c"
      },
      "source": [
        " \n",
        "fig, ax = plt.subplots(2,1)\n",
        "ax[0].plot(hist.history['loss'], color='b', label=\"Training loss\")\n",
        "ax[0].plot(hist.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "ax[1].plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "ax[1].plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u807t9ZQxJh_"
      },
      "source": [
        "##**XGBoost for Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW1ebwt9-qQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34229576-d3bc-40e2-ffe9-e2c5daf78e99"
      },
      "source": [
        "feature_extractor=base_model.predict(x_train)\n",
        "\n",
        "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
        "\n",
        "X_for_training = features #This is our X input to RF\n",
        "\n",
        "#RANDOM FOREST\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "#model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "y_train_label=np.where(y_train==1)[1]\n",
        "\n",
        "#XGBOOST\n",
        "import xgboost as xgb\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(X_for_training, y_train_label) #For sklearn no one hot encoding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VakKiJFa-xtO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "032ab3ab-334f-42ac-99b3-f25fd784bb6d"
      },
      "source": [
        "import seaborn as sns\n",
        "X_test_feature = base_model.predict(x_dev)\n",
        "X_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)\n",
        "\n",
        "#Now predict using the trained RF model. \n",
        "prediction = model.predict(X_test_features)\n",
        "#Inverse le transform to get original label back. \n",
        "# prediction = le.inverse_transform(prediction)\n",
        "y_test=np.where(y_dev==1)[1]\n",
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction))\n",
        "\n",
        "#Confusion Matrix - verify accuracy of each class\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, prediction)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.8033333333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe077064290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2L53jeeAV4T"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBRq4UQ0Abf7"
      },
      "source": [
        "pred=model.predict(X_test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSNAcCTPA3f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f45140-2fde-46d7-8f7b-58d49784f9ef"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.96      0.83       301\n",
            "           1       0.94      0.65      0.77       299\n",
            "\n",
            "    accuracy                           0.80       600\n",
            "   macro avg       0.84      0.80      0.80       600\n",
            "weighted avg       0.84      0.80      0.80       600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXLBp6MKt5yO"
      },
      "source": [
        "# **VGG16**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEMckdZet5oy"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization,Dropout,MaxPooling2D\n",
        "from tensorflow.keras.regularizers import l1,l2,l1_l2\n",
        "\n",
        "base_model = VGG16(input_shape=(224,224,3),include_top=False,weights='imagenet')\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "x=base_model.output\n",
        "x=Conv2D(1024,(3,3),padding='same',activation='relu')(x)\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Flatten()(x)\n",
        "x=Dense(1024,activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(x)\n",
        "x=Dropout(0.3)(x)\n",
        "x=Dense(16,activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(x)\n",
        "x=Dense(2,activation='softmax')(x)\n",
        "model=Model(base_model.input,x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni61FaIMxTm-"
      },
      "source": [
        "##**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpy3t40tuKod",
        "outputId": "7758d9c3-bd8b-434a-9e41-ec8f4d0c7057"
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 16)                16400     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 20,500,338\n",
            "Trainable params: 5,785,650\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpOCzb2WuNDZ"
      },
      "source": [
        "epochs = 100\n",
        "batch_size = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osgqaDDlxrGL"
      },
      "source": [
        "##**Early Stopping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dESBtNmquNf7"
      },
      "source": [
        "import keras\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=13,verbose=1,restore_best_weights=True)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.22, patience = 6, verbose = 1, \n",
        "                                              min_delta = 0.0001,min_lr=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YS5JXXzuPhC",
        "outputId": "a15fb395-8949-45a6-f0ec-e5630c4eac53"
      },
      "source": [
        "hist = model.fit(x_train,y_train,\n",
        "                 epochs = epochs,\n",
        "                validation_data = (x_dev,y_dev),\n",
        "                callbacks = [early_stop,reduce_lr],\n",
        "                verbose=1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "75/75 [==============================] - 26s 254ms/step - loss: 7.9037 - accuracy: 0.5754 - val_loss: 2.3877 - val_accuracy: 0.7450\n",
            "Epoch 2/100\n",
            "75/75 [==============================] - 13s 173ms/step - loss: 2.0206 - accuracy: 0.7686 - val_loss: 1.2813 - val_accuracy: 0.7750\n",
            "Epoch 3/100\n",
            "75/75 [==============================] - 13s 167ms/step - loss: 1.1303 - accuracy: 0.7793 - val_loss: 0.8814 - val_accuracy: 0.7850\n",
            "Epoch 4/100\n",
            "75/75 [==============================] - 12s 166ms/step - loss: 0.7916 - accuracy: 0.7993 - val_loss: 0.6854 - val_accuracy: 0.7800\n",
            "Epoch 5/100\n",
            "75/75 [==============================] - 12s 166ms/step - loss: 0.6190 - accuracy: 0.7895 - val_loss: 0.5782 - val_accuracy: 0.7817\n",
            "Epoch 6/100\n",
            "75/75 [==============================] - 13s 169ms/step - loss: 0.5367 - accuracy: 0.8152 - val_loss: 0.5320 - val_accuracy: 0.7867\n",
            "Epoch 7/100\n",
            "75/75 [==============================] - 13s 172ms/step - loss: 0.4885 - accuracy: 0.8082 - val_loss: 0.5390 - val_accuracy: 0.7833\n",
            "Epoch 8/100\n",
            "75/75 [==============================] - 13s 174ms/step - loss: 0.4707 - accuracy: 0.8103 - val_loss: 0.5021 - val_accuracy: 0.7800\n",
            "Epoch 9/100\n",
            "75/75 [==============================] - 13s 172ms/step - loss: 0.4243 - accuracy: 0.8278 - val_loss: 0.4841 - val_accuracy: 0.7883\n",
            "Epoch 10/100\n",
            "75/75 [==============================] - 13s 170ms/step - loss: 0.4073 - accuracy: 0.8287 - val_loss: 0.5928 - val_accuracy: 0.7167\n",
            "Epoch 11/100\n",
            "75/75 [==============================] - 13s 169ms/step - loss: 0.4202 - accuracy: 0.8149 - val_loss: 0.5156 - val_accuracy: 0.7517\n",
            "Epoch 12/100\n",
            "75/75 [==============================] - 13s 169ms/step - loss: 0.3806 - accuracy: 0.8461 - val_loss: 0.5061 - val_accuracy: 0.7767\n",
            "Epoch 13/100\n",
            "75/75 [==============================] - 13s 170ms/step - loss: 0.3492 - accuracy: 0.8597 - val_loss: 0.5291 - val_accuracy: 0.7567\n",
            "Epoch 14/100\n",
            "75/75 [==============================] - 13s 171ms/step - loss: 0.3436 - accuracy: 0.8639 - val_loss: 0.4884 - val_accuracy: 0.7850\n",
            "Epoch 15/100\n",
            "75/75 [==============================] - 13s 171ms/step - loss: 0.3607 - accuracy: 0.8562 - val_loss: 0.5464 - val_accuracy: 0.7800\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00022000001044943928.\n",
            "Epoch 16/100\n",
            "75/75 [==============================] - 13s 171ms/step - loss: 0.2833 - accuracy: 0.8916 - val_loss: 0.5520 - val_accuracy: 0.7583\n",
            "Epoch 17/100\n",
            "75/75 [==============================] - 13s 170ms/step - loss: 0.2635 - accuracy: 0.9060 - val_loss: 0.5696 - val_accuracy: 0.7433\n",
            "Epoch 18/100\n",
            "75/75 [==============================] - 13s 170ms/step - loss: 0.2573 - accuracy: 0.9134 - val_loss: 0.5630 - val_accuracy: 0.7850\n",
            "Epoch 19/100\n",
            "75/75 [==============================] - 13s 170ms/step - loss: 0.2619 - accuracy: 0.9121 - val_loss: 0.6235 - val_accuracy: 0.7650\n",
            "Epoch 20/100\n",
            "75/75 [==============================] - 13s 170ms/step - loss: 0.2358 - accuracy: 0.9205 - val_loss: 0.6288 - val_accuracy: 0.7467\n",
            "Epoch 21/100\n",
            "75/75 [==============================] - 13s 170ms/step - loss: 0.2250 - accuracy: 0.9248 - val_loss: 0.6221 - val_accuracy: 0.7850\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "Epoch 22/100\n",
            "75/75 [==============================] - 13s 169ms/step - loss: 0.2105 - accuracy: 0.9317 - val_loss: 0.6766 - val_accuracy: 0.7450\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00022: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RJ7QytRxuyM"
      },
      "source": [
        "##**Loss and accuracy plots for training and validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "M7HId3mtuTmB",
        "outputId": "2052e360-2d29-41cd-9926-50144c7f3420"
      },
      "source": [
        "# Plot the loss and accuracy curves for training and validation \n",
        "fig, ax = plt.subplots(2,1)\n",
        "ax[0].plot(hist.history['loss'], color='b', label=\"Training loss\")\n",
        "ax[0].plot(hist.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "ax[1].plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "ax[1].plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASjwv3kPxXe4"
      },
      "source": [
        "##**XGBoost for Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iirD1r4huT9p",
        "outputId": "edb33ddb-cd1e-47e8-8d8d-4530b54d9f27"
      },
      "source": [
        "feature_extractor=base_model.predict(x_train)\n",
        "\n",
        "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
        "\n",
        "X_for_training = features #This is our X input to RF\n",
        "\n",
        "#RANDOM FOREST\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "#model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "y_train_label=np.where(y_train==1)[1]\n",
        "\n",
        "#XGBOOST\n",
        "import xgboost as xgb\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(X_for_training, y_train_label) #For sklearn no one hot encoding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "Jyo1Fu2XuW3y",
        "outputId": "6bfc3c53-b160-4056-f3c2-35b23b2a2018"
      },
      "source": [
        "import seaborn as sns\n",
        "X_test_feature = base_model.predict(x_dev)\n",
        "X_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)\n",
        "\n",
        "#Now predict using the trained RF model. \n",
        "prediction = model.predict(X_test_features)\n",
        "#Inverse le transform to get original label back. \n",
        "# prediction = le.inverse_transform(prediction)\n",
        "y_test=np.where(y_dev==1)[1]\n",
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction))\n",
        "\n",
        "#Confusion Matrix - verify accuracy of each class\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, prediction)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.7716666666666666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe06e1687d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DO7_jt1uY0d"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JqmufYfucC0"
      },
      "source": [
        "pred=model.predict(X_test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsIAaBYbucGL",
        "outputId": "bd14a49b-0348-4c22-e205-6dcb7b2097c5"
      },
      "source": [
        "# print(\"Loss of the model is - \" , model.evaluate(X_test_features,y_test)[0])\n",
        "# print(\"Accuracy of the model is - \" , model.evaluate(X_test_features,y_test)[1]*100 , \"%\")\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.86      0.79       301\n",
            "           1       0.83      0.69      0.75       299\n",
            "\n",
            "    accuracy                           0.77       600\n",
            "   macro avg       0.78      0.77      0.77       600\n",
            "weighted avg       0.78      0.77      0.77       600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AdLYPJz34ii"
      },
      "source": [
        "#**InceptionV3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jzz3e3q2Qyn",
        "outputId": "a601a142-db2d-4554-b2bd-f3c204c0bf8d"
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization,Dropout,MaxPooling2D\n",
        "from tensorflow.keras.regularizers import l1,l2,l1_l2\n",
        "\n",
        "base_model = InceptionV3(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
        "\n",
        "#base_model = VGG16(input_shape=(224,224,3),include_top=False,weights='imagenet')\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "x=base_model.output\n",
        "x=Conv2D(1024,(3,3),padding='same',activation='relu')(x)\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Flatten()(x)\n",
        "x=Dense(1024,activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(x)\n",
        "x=Dropout(0.3)(x)\n",
        "x=Dense(16,activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(x)\n",
        "x=Dense(2,activation='softmax')(x)\n",
        "model=Model(base_model.input,x)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARRqK28s4EsA"
      },
      "source": [
        "##**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIysJGRy2hZz",
        "outputId": "915d4318-8823-4a99-932e-273dc4657b2b"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 111, 111, 32) 864         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 25, 25, 32)   96          conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 25, 25, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 25, 25, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 25, 25, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 25, 25, 48)   144         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 25, 25, 96)   288         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 25, 25, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 25, 25, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 25, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 25, 25, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 25, 25, 64)   192         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 25, 25, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 25, 25, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 25, 25, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 25, 25, 48)   144         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 25, 25, 96)   288         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 25, 25, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 25, 25, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 25, 25, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 25, 25, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 25, 25, 64)   192         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 25, 25, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 25, 25, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 25, 25, 64)   192         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 25, 25, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 25, 25, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 25, 25, 96)   288         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 25, 25, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 12, 12, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 12, 12, 384)  1152        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 12, 12, 96)   288         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 12, 12, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 12, 12, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 12, 12, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 12, 12, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 12, 12, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 12, 12, 192)  576         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 12, 12, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 12, 12, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 12, 12, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 12, 12, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 12, 12, 192)  576         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 12, 12, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 12, 12, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 12, 12, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 12, 12, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 12, 12, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 12, 12, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 12, 12, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 12, 12, 192)  576         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 12, 12, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 12, 12, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 5, 5, 320)    960         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 5, 5, 192)    576         conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 5, 5, 448)    1344        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 5, 5, 320)    960         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 5, 5, 192)    576         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 5, 5, 448)    1344        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 5, 5, 320)    960         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 5, 5, 192)    576         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 5, 5, 1024)   18875392    mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 1024)         0           conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 1024)         0           global_average_pooling2d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1024)         1049600     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 1024)         0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 16)           16400       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 2)            34          dense_7[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 41,744,210\n",
            "Trainable params: 19,941,426\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz-jczlG2zWj"
      },
      "source": [
        "epochs = 100\n",
        "batch_size = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ab0jY774N5B"
      },
      "source": [
        "##**Early Stopping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSaS0zrE2zZY"
      },
      "source": [
        "import keras\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=13,verbose=1,restore_best_weights=True)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.22, patience = 6, verbose = 1, \n",
        "                                              min_delta = 0.0001,min_lr=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FVCNDVr2zbs",
        "outputId": "92ff4654-517c-46a5-976b-24646a086e4f"
      },
      "source": [
        "hist = model.fit(x_train,y_train,\n",
        "                 epochs = epochs,\n",
        "                validation_data = (x_dev,y_dev),\n",
        "                callbacks = [early_stop,reduce_lr],\n",
        "                verbose=1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "75/75 [==============================] - 18s 160ms/step - loss: 10.3163 - acc: 0.6797 - val_loss: 7.9752 - val_acc: 0.7517\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 2/100\n",
            "75/75 [==============================] - 9s 125ms/step - loss: 7.3145 - acc: 0.7376 - val_loss: 5.4761 - val_acc: 0.7667\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 3/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 4.9951 - acc: 0.7477 - val_loss: 3.6650 - val_acc: 0.7667\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 4/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 3.3123 - acc: 0.7783 - val_loss: 2.4490 - val_acc: 0.7600\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 5/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 2.1998 - acc: 0.7714 - val_loss: 1.6942 - val_acc: 0.7467\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 6/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 1.5341 - acc: 0.7674 - val_loss: 1.1978 - val_acc: 0.7767\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 7/100\n",
            "75/75 [==============================] - 9s 121ms/step - loss: 1.1073 - acc: 0.7796 - val_loss: 0.9498 - val_acc: 0.7733\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 8/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.8727 - acc: 0.7877 - val_loss: 0.8186 - val_acc: 0.7767\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 9/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.7533 - acc: 0.7882 - val_loss: 0.7358 - val_acc: 0.7700\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 10/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.6725 - acc: 0.7885 - val_loss: 0.9919 - val_acc: 0.6517\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 11/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.6315 - acc: 0.7799 - val_loss: 0.6705 - val_acc: 0.7767\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 12/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.5462 - acc: 0.8186 - val_loss: 0.6151 - val_acc: 0.7783\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 13/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.5240 - acc: 0.7984 - val_loss: 0.6184 - val_acc: 0.7783\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 14/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.4665 - acc: 0.8268 - val_loss: 0.5923 - val_acc: 0.7800\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 15/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.4534 - acc: 0.8237 - val_loss: 0.6499 - val_acc: 0.6933\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 16/100\n",
            "75/75 [==============================] - 9s 121ms/step - loss: 0.4253 - acc: 0.8371 - val_loss: 0.6487 - val_acc: 0.7833\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 17/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.4034 - acc: 0.8575 - val_loss: 0.6658 - val_acc: 0.7750\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 18/100\n",
            "75/75 [==============================] - 9s 121ms/step - loss: 0.3657 - acc: 0.8691 - val_loss: 0.6517 - val_acc: 0.6850\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 19/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.3423 - acc: 0.8790 - val_loss: 0.5679 - val_acc: 0.7633\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 20/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.3203 - acc: 0.8849 - val_loss: 0.6024 - val_acc: 0.7767\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 21/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.3116 - acc: 0.8892 - val_loss: 0.7024 - val_acc: 0.7783\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 22/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.3028 - acc: 0.8931 - val_loss: 0.7142 - val_acc: 0.7900\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 23/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.2591 - acc: 0.9094 - val_loss: 0.6238 - val_acc: 0.7483\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 24/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.2517 - acc: 0.9259 - val_loss: 0.7082 - val_acc: 0.7433\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 25/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.2826 - acc: 0.9059 - val_loss: 0.6798 - val_acc: 0.7783\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 26/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.2212 - acc: 0.9350 - val_loss: 0.7556 - val_acc: 0.7867\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 27/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.2244 - acc: 0.9309 - val_loss: 0.6905 - val_acc: 0.7750\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 28/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1868 - acc: 0.9473 - val_loss: 0.7913 - val_acc: 0.6933\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 29/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1898 - acc: 0.9503 - val_loss: 0.7920 - val_acc: 0.7850\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 30/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1900 - acc: 0.9491 - val_loss: 0.7059 - val_acc: 0.7483\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 31/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1662 - acc: 0.9616 - val_loss: 0.8419 - val_acc: 0.7717\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 32/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.2357 - acc: 0.9354 - val_loss: 0.8156 - val_acc: 0.7567\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 33/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.1655 - acc: 0.9663 - val_loss: 0.7558 - val_acc: 0.7283\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 34/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1242 - acc: 0.9823 - val_loss: 0.7500 - val_acc: 0.7700\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 35/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1407 - acc: 0.9720 - val_loss: 0.9854 - val_acc: 0.7000\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 36/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1346 - acc: 0.9742 - val_loss: 0.9050 - val_acc: 0.7683\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 37/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1868 - acc: 0.9676 - val_loss: 0.8782 - val_acc: 0.7717\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 38/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1947 - acc: 0.9641 - val_loss: 0.8788 - val_acc: 0.7183\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 39/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1287 - acc: 0.9816 - val_loss: 0.8978 - val_acc: 0.7783\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 40/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1546 - acc: 0.9662 - val_loss: 0.7636 - val_acc: 0.7683\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 41/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1115 - acc: 0.9837 - val_loss: 0.7960 - val_acc: 0.7583\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 42/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.1120 - acc: 0.9837 - val_loss: 0.8622 - val_acc: 0.7650\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 43/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1020 - acc: 0.9829 - val_loss: 0.8675 - val_acc: 0.7550\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 44/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.0983 - acc: 0.9857 - val_loss: 0.7999 - val_acc: 0.7650\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 45/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.0932 - acc: 0.9871 - val_loss: 0.8893 - val_acc: 0.7383\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 46/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1065 - acc: 0.9847 - val_loss: 0.8387 - val_acc: 0.7583\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 47/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0991 - acc: 0.9829 - val_loss: 0.9204 - val_acc: 0.7650\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 48/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.1297 - acc: 0.9735 - val_loss: 0.9283 - val_acc: 0.7350\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 49/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0948 - acc: 0.9875 - val_loss: 0.9175 - val_acc: 0.7600\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 50/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1048 - acc: 0.9838 - val_loss: 0.9024 - val_acc: 0.7500\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 51/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1311 - acc: 0.9691 - val_loss: 0.8598 - val_acc: 0.7800\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 52/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.0886 - acc: 0.9898 - val_loss: 0.8050 - val_acc: 0.7567\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 53/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.0646 - acc: 0.9951 - val_loss: 0.9603 - val_acc: 0.7600\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 54/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1758 - acc: 0.9673 - val_loss: 1.2656 - val_acc: 0.7700\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 55/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1438 - acc: 0.9750 - val_loss: 0.9557 - val_acc: 0.7583\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 56/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.1039 - acc: 0.9771 - val_loss: 1.0161 - val_acc: 0.7750\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 57/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.0952 - acc: 0.9856 - val_loss: 2.0195 - val_acc: 0.7333\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 58/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1130 - acc: 0.9852 - val_loss: 0.8900 - val_acc: 0.7500\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 59/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1243 - acc: 0.9768 - val_loss: 0.9414 - val_acc: 0.7283\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 60/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0918 - acc: 0.9826 - val_loss: 0.9020 - val_acc: 0.7583\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 61/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.0770 - acc: 0.9889 - val_loss: 0.9421 - val_acc: 0.7717\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 62/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0978 - acc: 0.9841 - val_loss: 0.8978 - val_acc: 0.7517\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 63/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.0842 - acc: 0.9904 - val_loss: 0.8167 - val_acc: 0.7583\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 64/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0601 - acc: 0.9925 - val_loss: 0.8128 - val_acc: 0.7583\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 65/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.0588 - acc: 0.9941 - val_loss: 0.9717 - val_acc: 0.7600\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 66/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.1343 - acc: 0.9736 - val_loss: 0.9599 - val_acc: 0.7567\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 67/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0989 - acc: 0.9809 - val_loss: 0.9553 - val_acc: 0.7250\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 68/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.1549 - acc: 0.9627 - val_loss: 0.8697 - val_acc: 0.7667\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 69/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0851 - acc: 0.9905 - val_loss: 1.0129 - val_acc: 0.7717\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 70/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.1408 - acc: 0.9745 - val_loss: 0.9671 - val_acc: 0.7633\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 71/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.1200 - acc: 0.9774 - val_loss: 1.3960 - val_acc: 0.7550\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 72/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1738 - acc: 0.9555 - val_loss: 0.8738 - val_acc: 0.7667\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 73/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0805 - acc: 0.9879 - val_loss: 0.9834 - val_acc: 0.7733\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 74/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.1164 - acc: 0.9824 - val_loss: 0.9710 - val_acc: 0.7700\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 75/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0538 - acc: 0.9925 - val_loss: 0.9634 - val_acc: 0.7667\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 76/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.1132 - acc: 0.9798 - val_loss: 0.8376 - val_acc: 0.7450\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 77/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0487 - acc: 0.9970 - val_loss: 0.8887 - val_acc: 0.7583\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 78/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0630 - acc: 0.9888 - val_loss: 0.8821 - val_acc: 0.7550\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 79/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0774 - acc: 0.9901 - val_loss: 0.9594 - val_acc: 0.7617\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 80/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.1371 - acc: 0.9757 - val_loss: 0.8970 - val_acc: 0.7533\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 81/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0797 - acc: 0.9895 - val_loss: 0.9880 - val_acc: 0.6900\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 82/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0475 - acc: 0.9944 - val_loss: 0.9622 - val_acc: 0.7817\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 83/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.1130 - acc: 0.9803 - val_loss: 0.8794 - val_acc: 0.7500\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 84/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0388 - acc: 0.9978 - val_loss: 0.9373 - val_acc: 0.7533\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 85/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0751 - acc: 0.9880 - val_loss: 1.0389 - val_acc: 0.7483\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 86/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.1281 - acc: 0.9835 - val_loss: 0.9478 - val_acc: 0.7383\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 87/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0772 - acc: 0.9837 - val_loss: 1.2011 - val_acc: 0.6867\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 88/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.1259 - acc: 0.9707 - val_loss: 0.8694 - val_acc: 0.7567\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 89/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0459 - acc: 0.9931 - val_loss: 1.0039 - val_acc: 0.7700\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 90/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0927 - acc: 0.9875 - val_loss: 0.9289 - val_acc: 0.7717\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 91/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0931 - acc: 0.9805 - val_loss: 0.8894 - val_acc: 0.7733\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 92/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0372 - acc: 0.9969 - val_loss: 0.8940 - val_acc: 0.7450\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 93/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0477 - acc: 0.9909 - val_loss: 0.9928 - val_acc: 0.7350\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 94/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.1030 - acc: 0.9762 - val_loss: 0.9181 - val_acc: 0.7467\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 95/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.0391 - acc: 0.9969 - val_loss: 0.9055 - val_acc: 0.7700\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 96/100\n",
            "75/75 [==============================] - 9s 122ms/step - loss: 0.0418 - acc: 0.9967 - val_loss: 1.9706 - val_acc: 0.7100\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 97/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.1252 - acc: 0.9758 - val_loss: 0.8970 - val_acc: 0.7717\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 98/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0382 - acc: 0.9965 - val_loss: 0.8468 - val_acc: 0.7500\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 99/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0350 - acc: 0.9984 - val_loss: 0.9088 - val_acc: 0.7550\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n",
            "Epoch 100/100\n",
            "75/75 [==============================] - 9s 123ms/step - loss: 0.0569 - acc: 0.9891 - val_loss: 0.9689 - val_acc: 0.7450\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,acc,val_loss,val_acc,lr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgoX71kF4TMJ"
      },
      "source": [
        "##**Loss and accuracy plots for training and validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "UzamVs2s2zea",
        "outputId": "7476330e-fc42-4dc5-a2f0-90d4dc6b2023"
      },
      "source": [
        "fig, ax = plt.subplots(2,1)\n",
        "ax[0].plot(hist.history['loss'], color='b', label=\"Training loss\")\n",
        "ax[0].plot(hist.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "ax[1].plot(hist.history['acc'], color='b', label=\"Training accuracy\")\n",
        "ax[1].plot(hist.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42IBQHkF4Ytj"
      },
      "source": [
        "##**XGBoost for Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOa9YGj32zg8",
        "outputId": "2ae2c6cc-767c-4216-d91f-c6bed638a5e1"
      },
      "source": [
        "feature_extractor=base_model.predict(x_train)\n",
        "\n",
        "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
        "\n",
        "X_for_training = features #This is our X input to RF\n",
        "\n",
        "# Train the model on training data\n",
        "y_train_label=np.where(y_train==1)[1]\n",
        "\n",
        "#XGBOOST\n",
        "import xgboost as xgb\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(X_for_training, y_train_label) #For sklearn no one hot encoding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "oiDVm0fD3JZL",
        "outputId": "8ca18537-4c15-46e1-9765-bbb575dbe551"
      },
      "source": [
        "import seaborn as sns\n",
        "X_test_feature = base_model.predict(x_dev)\n",
        "X_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)\n",
        "\n",
        "#Now predict using the trained RF model. \n",
        "prediction = model.predict(X_test_features)\n",
        "#Inverse le transform to get original label back. \n",
        "# prediction = le.inverse_transform(prediction)\n",
        "y_test=np.where(y_dev==1)[1]\n",
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction))\n",
        "\n",
        "#Confusion Matrix - verify accuracy of each class\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, prediction)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  0.76\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe02e481a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDi2JeDW3JbB"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vgb0JZb3JeT"
      },
      "source": [
        "pred=model.predict(X_test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoibPbQ-3RSx",
        "outputId": "dac0f403-d11f-458d-fa4f-1dfd2cb6b9b1"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.89      0.79       301\n",
            "           1       0.85      0.63      0.72       299\n",
            "\n",
            "    accuracy                           0.76       600\n",
            "   macro avg       0.78      0.76      0.76       600\n",
            "weighted avg       0.78      0.76      0.76       600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6anmCHf9sJk",
        "outputId": "bde3638f-f59e-445d-9b54-519f6a409ae0"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, pred)\n",
        "print(\"Accuracy: %.2f\" % (accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUo1THBs90kh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}